import customtkinter as ctk
import pvporcupine
from pvrecorder import PvRecorder
import threading
import time
import os
import json
import whisper
import requests
import functools
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import os.path
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
import subprocess
import sys
import logging

try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False

import traceback
import signal
import tempfile
import shutil
import wave
import numpy as np
import collections
import re
from flask import Flask, request, jsonify
from datetime import datetime, timedelta
from dataclasses import dataclass, field

# Add project root to Python path to resolve local modules like 'core'
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)
from vault_reference import VaultReference
from memory_index import MemoryIndex
from dashboard_bridge import DashboardBridge
from core.context_manager import ShortKeyGenerator, SessionContext as NewSessionContext, ConversationalLedger

# Load environment variables from .env file
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # dotenv not installed, continue with os.getenv

# Location Configuration
LOCATION_OVERRIDE = "Kent,UK"
LATITUDE = 51.172096
LONGITUDE = 0.498793

# Define what Jarvis is allowed to do
SCOPES = [
    'https://www.googleapis.com/auth/gmail.send',
    'https://www.googleapis.com/auth/gmail.readonly',
    'https://www.googleapis.com/auth/calendar',
    'https://www.googleapis.com/auth/documents',
    'https://www.googleapis.com/auth/drive.file',
    'https://www.googleapis.com/auth/spreadsheets'
]

def check_credentials():
    """
    Check for required credential files and log warnings if missing.
    """
    missing_files = []
    
    if not os.path.exists('credentials.json'):
        missing_files.append('credentials.json')
    
    if not os.path.exists('token.json'):
        missing_files.append('token.json')
    
    if missing_files:
        print("\n" + "="*60)
        print("WARNING: MISSING CREDENTIAL FILES")
        print("="*60)
        for file in missing_files:
            print(f"  ‚úó {file} not found in current directory")
        print("\nGoogle API integration will fail without these files.")
        print("Please ensure credentials.json and token.json are present.")
        print("="*60 + "\n")
        return False
    else:
        print("‚úì Credentials check passed: credentials.json and token.json found.")
        return True

def get_google_creds():
    creds = None
    # The file token.json stores the user's access and refresh tokens
    if os.path.exists('token.json'):
        creds = Credentials.from_authorized_user_file('token.json', SCOPES)
    
    # If there are no (valid) credentials available, let the user log in.
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            # This looks for your 'credentials.json' (the one with Client ID/Secret)
            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)
            creds = flow.run_local_server(port=0)
        
        # Save the credentials for the next run
        with open('token.json', 'w') as token:
            token.write(creds.to_json())
    return creds



# --- CONFIGURATION ---
# Load configuration from config.json with .env overrides
def load_config():
    """Load config from config.json with environment variable overrides.
    Environment variables (.env) take priority for secrets.
    If config.json doesn't exist, all values must come from .env.
    """
    config = {}
    try:
        with open('config.json', 'r') as f:
            config = json.load(f)
    except FileNotFoundError:
        print("INFO: config.json not found - using .env only")
    except json.JSONDecodeError as e:
        print(f"ERROR: Invalid JSON in config.json: {e}")
        sys.exit(1)
    
    # Load secrets from environment variables (.env) with fallback to config.json
    picovoice_key = os.getenv("PICOVOICE_KEY") or config.get("picovoice_key")
    google_client_id = os.getenv("GOOGLE_CLIENT_ID") or config.get("google_client_id")
    google_client_secret = os.getenv("GOOGLE_CLIENT_SECRET") or config.get("google_client_secret")
    google_project_id = os.getenv("GOOGLE_PROJECT_ID") or config.get("google_project_id")
    google_cse_api_key = os.getenv("GOOGLE_CSE_API_KEY") or config.get("google_cse_api_key")
    google_cse_cx = os.getenv("GOOGLE_CSE_CX") or config.get("google_cse_cx")
    google_drive_folder_id = os.getenv("GOOGLE_DRIVE_FOLDER_ID") or config.get("google_drive_folder_id")
    google_drive_folder_source_doc_id = os.getenv("GOOGLE_DRIVE_FOLDER_SOURCE_DOC_ID") or config.get("google_drive_folder_source_doc_id")
    owner_email = os.getenv("OWNER_EMAIL") or config.get("owner_email")
    brain_url = os.getenv("BRAIN_URL") or config.get("brain_url", "http://localhost:11434/api/generate")
    llm_model = os.getenv("LLM_MODEL") or config.get("llm_model", "llama3.1:8b")
    piper_exe = os.getenv("PIPER_EXE") or config.get("piper_exe")
    perplexity_api_key = os.getenv("PERPLEXITY_API_KEY") or config.get("perplexity_api_key")
    
    # VAD Settings for barge-in and adaptive listening
    # Environment variables take priority over config.json
    config_vad = config.get("vad_settings", {})
    vad_settings = {
        "energy_threshold": int(os.getenv("VAD_ENERGY_THRESHOLD", config_vad.get("energy_threshold", 500))),
        "silence_duration": float(os.getenv("VAD_SILENCE_DURATION", config_vad.get("silence_duration", 1.2))),
        "min_speech_duration": float(os.getenv("VAD_MIN_SPEECH_DURATION", config_vad.get("min_speech_duration", 0.5))),
        "barge_in_enabled": os.getenv("VAD_BARGE_IN_ENABLED", str(config_vad.get("barge_in_enabled", False))).lower() == "true",
        "barge_in_threshold": int(os.getenv("VAD_BARGE_IN_THRESHOLD", config_vad.get("barge_in_threshold", 1500))),
        "barge_in_delay": float(os.getenv("VAD_BARGE_IN_DELAY", config_vad.get("barge_in_delay", 1.0)))
    }
    
    return {
        "picovoice_key": picovoice_key,
        "google_client_id": google_client_id,
        "google_client_secret": google_client_secret,
        "google_project_id": google_project_id,
        "google_cse_api_key": google_cse_api_key,
        "google_cse_cx": google_cse_cx,
        "google_drive_folder_id": google_drive_folder_id,
        "google_drive_folder_source_doc_id": google_drive_folder_source_doc_id,
        "owner_email": owner_email,
        "brain_url": brain_url,
        "llm_model": llm_model,
        "piper_exe": piper_exe,
        "perplexity_api_key": perplexity_api_key,
        "vad_settings": vad_settings
    }

# Load configuration
config_dict = load_config()
PICOVOICE_KEY = config_dict["picovoice_key"]
GOOGLE_CLIENT_ID = config_dict["google_client_id"]
GOOGLE_CLIENT_SECRET = config_dict["google_client_secret"]
GOOGLE_PROJECT_ID = config_dict["google_project_id"]
GOOGLE_CSE_API_KEY = config_dict["google_cse_api_key"]
GOOGLE_CSE_CX = config_dict["google_cse_cx"]
GOOGLE_DRIVE_FOLDER_ID = config_dict["google_drive_folder_id"]
GOOGLE_DRIVE_FOLDER_SOURCE_DOC_ID = config_dict["google_drive_folder_source_doc_id"]
OWNER_EMAIL = config_dict["owner_email"]
BRAIN_URL = config_dict["brain_url"]
PERPLEXITY_API_KEY = config_dict.get("perplexity_api_key")
LLM_MODEL = config_dict["llm_model"]
VAD_SETTINGS = config_dict["vad_settings"]

# Configure logging ‚Äî console at INFO, rotating file at DEBUG
from logging.handlers import RotatingFileHandler as _RotatingFileHandler

_log_fmt = logging.Formatter('[%(asctime)s] %(levelname)s %(name)s: %(message)s', datefmt='%H:%M:%S')

_console_handler = logging.StreamHandler()
_console_handler.setLevel(logging.INFO)
_console_handler.setFormatter(_log_fmt)

_file_handler = _RotatingFileHandler(
    'jarvis.log', maxBytes=5 * 1024 * 1024, backupCount=3, encoding='utf-8')
_file_handler.setLevel(logging.DEBUG)
_file_handler.setFormatter(_log_fmt)

logging.root.setLevel(logging.DEBUG)
logging.root.addHandler(_console_handler)
logging.root.addHandler(_file_handler)

logger = logging.getLogger(__name__)

# Topic anchor nouns ‚Äî used by memory deduplication to identify a fact's subject.
# Two facts sharing ‚â•1 anchor noun are treated as being about the same topic.
_MEMORY_ANCHORS: frozenset = frozenset({
    'car', 'vehicle', 'van', 'truck', 'bike', 'motorcycle', 'scooter', 'transport',
    'job', 'work', 'role', 'company', 'employer', 'career', 'profession', 'salary',
    'occupation', 'business', 'office', 'client',
    'home', 'address', 'location', 'house', 'flat', 'apartment', 'town', 'city',
    'country', 'street', 'postcode', 'moved',
    'dog', 'cat', 'pet', 'fish', 'bird', 'animal', 'rabbit', 'hamster',
    'wife', 'husband', 'partner', 'girlfriend', 'boyfriend', 'spouse',
    'family', 'children', 'kids', 'son', 'daughter', 'parents', 'brother', 'sister',
    'health', 'pain', 'anxiety', 'medication', 'condition', 'illness',
    'depression', 'stress', 'therapy', 'diagnosis',
    'hobby', 'hobbies', 'passion', 'interest', 'sport', 'music', 'gaming',
    'phone', 'email', 'number', 'contact',
    'diet', 'food', 'eating', 'vegan', 'vegetarian',
    'drink', 'alcohol', 'coffee', 'tea',
    'sleep', 'routine', 'schedule', 'habit',
})

# --- INTENT DEFINITIONS ---
# The new score-based intent router uses these definitions.
# More specific intents should have higher-scoring keywords or 'required' words.
INTENTS = {
    "LEARN_FACT": {
        "keywords": ["remember that", "note that", "update your memory", "store that", "forget that", "no longer true", "correction:", "update:", "note:", "that's wrong"],
        "handler": "handle_learn_fact", "name": "update my memory"
    },
    "SELF_KNOWLEDGE": {
        "keywords": ["who are you", "what do you know about me", "tell me about yourself"],
        "handler": "handle_self_knowledge", "name": "ask about you or me"
    },
    "PROJECT_DOGZILLA": {"keywords": ["dogzilla"], "handler": "handle_dogzilla", "name": "ask about project Dogzilla"},
    "WEATHER": {"keywords": ["weather"], "handler": "handle_weather", "name": "check the weather"},
    "TASK": {
        "keywords": ["remind me", "reminder", "add to my list", "don't forget", "note to self", "remember to", "what's on my list", "my tasks", "show tasks", "list tasks", "what do i need to do", "done", "complete", "finished", "mark"],
        "handler": "handle_task_request", "name": "manage my tasks"
    },
    "MEMORY_RECALL": {
        "regex": r'\b(?:did|have)\s+(?:i|you|we)\s+(?:ever\s+)?\w',
        "handler": "handle_task_request", "name": "recall a past action"
    },
    "CALENDAR_READ": {
        "keywords": ["calendar", "what's my day", "diary", "upcoming", "schedule today", "what do i have", "what have i got"],
        "blockers": ["book", "schedule a", "add", "create", "move", "reschedule", "cancel"],
        "handler": "handle_calendar_read", "name": "check my calendar"
    },
    "CALENDAR_ACTION": {
        "keywords": ["book", "cancel", "reschedule", "move", "create an event", "add an event", "schedule a meeting", "schedule a call"],
        "handler": "handle_calendar_action", "name": "change my calendar"
    },
    "REPORT_RETRIEVAL": {
        "keywords": ["report", "optimization", "document", "summary"],
        "required": ["last", "latest", "recent"],
        "handler": "handle_report_retrieval", "name": "get the last report"
    },
    "CODE_OPTIMIZATION": {
        "keywords": ["analys", "optimise", "optimize", "summary", "report"],
        "required": ["file", "code", "script"],
        "handler": "handle_optimization_request", "name": "analyze a file"
    },
    "FILE_COMPARISON": {"keywords": ["compare", "comparison"], "handler": "handle_comparison_request", "name": "compare two files"},
    "EMAIL_SUMMARY": {
        "keywords": ["summarize", "summary", "read", "show"],
        "required": ["email", "emails", "mail"],
        "handler": "handle_email_summary_request", "name": "summarize my emails"
    },
    "EMAIL_SEARCH": {
        "keywords": ["search", "find", "look for"],
        "required": ["email", "emails", "mail from", "message from"],
        "handler": "handle_email_search_request", "name": "search my emails"
    },
    "EMAIL_REPLY": {
        "keywords": ["reply", "respond", "answer"],
        "required": ["email", "mail", "last message"],
        "handler": "handle_email_reply_request", "name": "reply to an email"
    },
    "EMAIL_MANAGEMENT": {
        "keywords": ["archive", "bin it", "trash it", "delete that email", "mark handled", "mark as read"],
        "handler": "handle_email_management_request", "name": "manage an email"
    },
    "WEB_SEARCH": {"keywords": ["search", "who is", "what is", "find", "google"], "handler": "handle_web_search", "name": "search the web"}
}

class JarvisGT2:
    def __init__(self):
        # Remove Tkinter GUI initialization - now headless with Cyber-Grid Dashboard
        # All UI handled by: http://localhost:5000
        
        # Create dummy status_var for compatibility (Tkinter removed)
        class DummyVar:
            def set(self, value): pass
        self.status_var = DummyVar()

        self.is_listening = False
        self.gaming_mode = False
        self.conversation_mode = False
        self.mic_muted = False
        self.last_interaction_time = time.time()
        
        # --- NEW: OpenVINO Whisper Integration ---
        logger.info("Loading Whisper STT model via OpenVINO...")
        self.stt_model = whisper.load_model("base", device="NPU") # Target NPU, will fallback to GPU/CPU
        logger.info(f"‚úì Whisper STT model offloaded to: {self.stt_model.device}")
        
        self.porcupine = None
        self.recorder = None
        self.wake_word_thread = None
        self.piper_available = self.check_piper_installation()
        self.yes_audio_path = "yes.wav"
        self.generate_yes_audio()
        
        # Short-term context buffer (last 5 exchanges)
        self.context_buffer = collections.deque(maxlen=5)
        
        # Long-term persistent memory
        self.memory_file = "jarvis_memory.json"
        self.memory = self.load_memory()
        
        # Indexed memory system for unlimited action history
        self.memory_index = MemoryIndex(memory_file=self.memory_file)
        
        # --- NEW: Visual Addressing & Context System ---
        self.short_key_generator = ShortKeyGenerator()
        self.session_context = NewSessionContext()
        self.conversational_ledger = ConversationalLedger(self.memory_index, self.short_key_generator)
        
        # Priority Notification Queue (n8n Integration)
        self.notification_queue = []
        self.urgent_interrupt = False
        self.notification_cooldown = 10  # seconds
        self.last_notification_speak_time = 0
        
        # Email deduplication (track seen email IDs for 1 hour)
        self.seen_email_ids = {}  # {email_id: timestamp}
        self.last_email_cleanup = time.time()
        
        # Audio synchronization (prevent speaking over self)
        self.speak_lock = threading.Lock()
        self.queue_lock = threading.Lock()

        # Pending email reply (awaiting confirmation before send)
        self.pending_reply = None  # {email_id, sender, sender_name, reply_text}

        # Intent context tracking (for conversational follow-ups)
        self.last_intent = None  # "email", "calendar", "task", "search", "optimization"
        self.last_calendar_events = []  # [{index, id, summary, start, start_dt}, ...]
        self.last_email_context = None  # For legacy context ("reply to that")
        self.pending_calendar_title = None  # Partial calendar entry awaiting time

        # Task / Reminder system
        self.tasks = []  # Populated after memory loads below

        # Health tracking for proactive interventions
        self.interaction_count = 0
        self.last_break_time = time.time()
        self.memory = self.load_memory()
        
        # VAD parameters - loaded from config
        self.vad_threshold = VAD_SETTINGS.get("energy_threshold", 500)
        self.silence_duration = VAD_SETTINGS.get("silence_duration", 1.2)
        self.min_speech_duration = VAD_SETTINGS.get("min_speech_duration", 0.5)
        self.barge_in_enabled = VAD_SETTINGS.get("barge_in_enabled", True)
        self.barge_in_threshold = VAD_SETTINGS.get("barge_in_threshold", 800)
        self.barge_in_delay = VAD_SETTINGS.get("barge_in_delay", 1.0)
        
        # Barge-in control flags
        self.is_speaking = False
        self.interrupt_requested = False
        self.vad_monitor_thread = None
        self.vad_monitor_active = False
        self.current_tts_process = None
        
        # Project Vault Configuration
        self.vault_root = r'C:\Users\spencer\Documents\Projects'
        self.active_project = 'New_Jarvis'  # Default project
        self.available_projects = []  # Will be populated on first scan
        self.scan_vault_projects()  # Initialize project list
        
        # Initialize Vault Reference System
        self.vault = VaultReference()
        if self.vault.is_loaded:
            logger.info("‚úì Vault index loaded - file reference system active")
            self.log("‚úì Vault reference system active")
        else:
            logger.warning("‚ö† Vault index not available - file searches may be limited")
            self.log("‚ö† Vault index not loaded - generate with: python create_vault_index.py")
        
        # Initialize Dashboard Bridge
        self.dashboard = DashboardBridge()
        self.dashboard.on_health_update = self.handle_health_update
        self.dashboard.on_state_change = self.handle_dashboard_state_change
        self.dashboard.start()
        
        logger.info("Jarvis GT2 initializing...")
        logger.info("üåê UI handled by Cyber-Grid Dashboard at http://localhost:5000") 
        logger.info("üîä Running in HEADLESS mode - no Tkinter GUI")
        logger.info("System initialized successfully")
        
        # Initialize n8n webhook listener for priority notifications
        self.setup_n8n_webhook()
        
        # Load tasks from persistent memory (must be after self.memory is loaded)
        self.tasks = self.memory.get("tasks", [])

        # Start reminder scheduler background thread
        self.reminder_thread = threading.Thread(target=self.reminder_scheduler_loop, daemon=True)
        self.reminder_thread.start()

        # Auto-start listening for wake word (Normal Mode)
        self.start_listening()

    def start_listening(self):
        """Start wake word detection automatically."""
        if not self.gaming_mode and not self.is_listening:
            self.log("üé§ Starting wake word detection...")
            logger.info("Auto-starting wake word detection (Normal Mode)")
            self.is_listening = True
            self.wake_word_thread = threading.Thread(target=self.run_wake_word_loop, daemon=True)
            self.wake_word_thread.start()
            logger.debug("Wake word loop thread started")

    def on_closing(self):
        """Handle window close event gracefully."""
        logger.info("Window close requested - shutting down...")
        self.log("Shutting down Jarvis...")
        
        # Stop dashboard bridge
        if hasattr(self, 'dashboard'):
            self.dashboard.push_state(mode="idle")  # Set to idle before shutdown
            self.dashboard.stop()
        
        # Stop listening
        self.is_listening = False
        self.gaming_mode = True  # Force stop all audio
        
        # Clean up resources
        self.cleanup_audio_resources()
        
        # Give threads time to finish
        time.sleep(0.5)
        
        logger.info("Shutdown complete")
        self.destroy()

    def log(self, text):
        """Log to system logger and dashboard (headless mode)."""
        logger.info(text)
        
        # Push to dashboard
        if hasattr(self, 'dashboard'):
            # Map log types
            level = "info"
            upper_text = text.upper()

            # AI responses are 'speak' level, not 'error', even if they contain "error"
            if "JARVIS:" in upper_text:
                level = "speak"
            elif "‚ùå" in text or "ERROR" in upper_text or "FAILED" in upper_text:
                level = "error"
            elif "‚ö†" in text or "WARN" in upper_text:
                level = "warn"
            elif "LISTENING" in upper_text or "WAKE WORD" in upper_text:
                level = "listen"
            elif "TRANSCRIB" in upper_text or "PROCESS" in upper_text or "ANALYZ" in upper_text:
                level = "process"
            elif "SPEAK" in upper_text or "TTS" in upper_text:
                level = "speak"
            elif "‚úì" in text or "SUCCESS" in upper_text or "COMPLETE" in upper_text:
                level = "success"
            
            self.dashboard.push_log(level, text)
    
    def load_memory(self):
        """Load persistent memory from jarvis_memory.json."""
        default_memory = {
            "master_location": LOCATION_OVERRIDE,
            "master_coordinates": {"latitude": LATITUDE, "longitude": LONGITUDE},
            "master_profile": {
                "name": "Spencer",
                "working_method": "Research ‚Üí Propose ‚Üí Test ‚Üí Verify",
                "communication_style": "Concise, low-friction, health-conscious",
                "health_profile": {
                    "chronic_pain": True,
                    "anxiety": True,
                    "stress_prone": True,
                    "depression_prone": True,
                    "recommended_break_interval": 90  # minutes
                }
            },
            "facts": [
                "I serve Spencer from Kent, UK",
                "My location is Kent with coordinates 51.172096, 0.498793",
                "I use Ollama with llama3.1:8b as my brain",
                "I can search the web and access Google services",
                "Spencer works using: Research ‚Üí Propose ‚Üí Test ‚Üí Verify method",
                "Spencer manages chronic pain and anxiety"
            ],
            "projects": {
                "dogzilla": {
                    "name": "Dogzilla",
                    "type": "ESP32-based robotics project",
                    "description": "Mobile robotics platform using ESP32 microcontroller",
                    "status": "Active Development",
                    "components": ["ESP32 microcontroller", "Motor drivers", "Sensors", "Custom firmware"]
                }
            },
            "conversation_history": [],
            "last_break_time": None,
            "interaction_count": 0
        }
        
        if os.path.exists(self.memory_file):
            try:
                with open(self.memory_file, 'r') as f:
                    memory = json.load(f)
                    logger.info("‚úì Memory loaded from disk")
                    return memory
            except Exception as e:
                logger.warning(f"Failed to load memory: {e}, using defaults")
                return default_memory
        else:
            logger.info("Creating new memory file...")
            self.save_memory(default_memory)
            return default_memory
    
    def save_memory(self, memory=None):
        """Save persistent memory to jarvis_memory.json using indexed system."""
        if memory is None:
            memory = self.memory
        try:
            # Save through memory index (handles vault_actions automatically)
            self.memory_index.save(memory)
            logger.info("‚úì Memory saved to disk")
        except Exception as e:
            logger.error(f"Failed to save memory: {e}")
    
    def handle_health_update(self, metric_type: str, level: int):
        """Handle health updates from dashboard (mood/pain tracker).
        
        Args:
            metric_type: "pain" or "anxiety"
            level: 0-4 (None, Mild, Moderate, Severe, Extreme)
        """
        level_names = ["None", "Mild", "Moderate", "Severe", "Extreme"]
        level_name = level_names[level] if 0 <= level < len(level_names) else "Unknown"
        
        # Log to memory
        health_record = {
            "timestamp": datetime.now().isoformat(),
            "type": metric_type,
            "level": level,
            "level_name": level_name
        }

        # Persist to health log file
        health_dir = os.path.join(os.path.dirname(__file__), "health")
        os.makedirs(health_dir, exist_ok=True)
        health_log_path = os.path.join(health_dir, "health_log.jsonl")
        health_snapshot_path = os.path.join(health_dir, "health_snapshot.json")
        try:
            with open(health_log_path, "a", encoding="utf-8") as log_file:
                log_file.write(json.dumps(health_record) + "\n")

            snapshot = {}
            if os.path.exists(health_snapshot_path):
                with open(health_snapshot_path, "r", encoding="utf-8") as snapshot_file:
                    snapshot = json.load(snapshot_file) or {}

            snapshot[metric_type] = {
                "level": level,
                "level_name": level_name,
                "timestamp": health_record["timestamp"]
            }
            with open(health_snapshot_path, "w", encoding="utf-8") as snapshot_file:
                json.dump(snapshot, snapshot_file, indent=2)
        except Exception as e:
            logger.error(f"Failed to write health log: {e}")
        
        # Store in memory
        if "health_logs" not in self.memory:
            self.memory["health_logs"] = []
        self.memory["health_logs"].append(health_record)
        self.save_memory()
        
        self.log(f"üìä Health logged: {metric_type.title()} = {level_name}")
        
        # If pain > 3 (Severe), respond with concern
        if metric_type == "pain" and level > 3:
            response = "I've logged your pain level, Sir. I will keep our responses concise to save your energy."
            self.log(f"Jarvis: {response}")
            self.speak_with_piper(response)
    
    def handle_dashboard_state_change(self, key: str, value: bool):
        """Handle state changes from dashboard UI toggles.
        
        Args:
            key: State key - "gamingMode", "muteMic", or "conversationalMode"
            value: New boolean value
        """
        if key == "gamingMode":
            self.gaming_mode = value
            if value:
                self.log("üéÆ Gaming Mode: ENABLED")
                self.log("   ‚Üí Mic disabled, resources freed")
                logger.info("Gaming mode activated - stopping all listening and freeing resources")
                self.is_listening = False
                self.dashboard.push_state(mode="idle", gamingMode=True)
            else:
                self.log("üéÆ Gaming Mode: DISABLED")
                self.log("   ‚Üí Resuming normal operation")
                logger.info("Gaming mode deactivated - resuming normal operation")
                self.dashboard.push_state(mode="idle", gamingMode=False)
                self.start_listening()

        elif key == "muteMic":
            self.mic_muted = value
            if value:
                self.log("üîá Microphone: MUTED")
                logger.info("Microphone muted - audio input will be ignored")
            else:
                self.log("üîä Microphone: UNMUTED")
                logger.info("Microphone unmuted - audio input active")
            self.dashboard.push_state(muteMic=value)

        elif key == "conversationalMode":
            self.conversation_mode = value
            if value:
                self.log("üí¨ Conversation Mode: ENABLED")
                self.log("   ‚Üí Open mic, natural dialogue")
                if not self.is_listening:
                    self.start_listening()
            else:
                self.log("üí¨ Conversation Mode: DISABLED")
                self.log("   ‚Üí Now requires wake word")
                self.conversation_mode = False
            self.dashboard.push_state(conversationalMode=value)
    
    
    def get_file_content(self, reference_name):
        """
        Resolve a file reference (like 'main file') to its path and read content.
        Uses the Vault Index to understand common references.
        
        Args:
            reference_name: User's reference like 'main', 'config', 'startup', etc.
        
        Returns:
            Dictionary with file path and content, or None if not found
        """
        if not self.vault or not self.vault.is_loaded:
            logger.warning("Vault not loaded - cannot resolve file reference")
            return None
        
        try:
            # Try to find the file using vault reference
            file_path = self.vault.get_file(reference_name.lower())
            
            if not file_path:
                # Try exact filename search
                file_path = self.vault.search_file(reference_name)
            
            if not file_path or not os.path.exists(file_path):
                logger.warning(f"File not found for reference: {reference_name}")
                return None
            
            # Read the file content
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            logger.info(f"‚úì Read file: {file_path} ({len(content)} bytes)")
            
            # Log file read action to memory
            self.log_vault_action(
                action_type="file_read",
                description=f"Read file: {os.path.basename(file_path)}",
                metadata={
                    "file_path": file_path,
                    "file_size": len(content),
                    "reference": reference_name
                }
            )
            
            return {
                'path': file_path,
                'filename': os.path.basename(file_path),
                'content': content,
                'size': len(content)
            }
            
        except Exception as e:
            logger.error(f"Error reading file: {e}")
            return None
    
    def write_optimization_to_doc(self, filename, report_content):
        """
        Scribe Capability: Write optimization report to Google Doc.
        
        Creates a formatted Google Doc with code analysis/optimization report.
        Automatically saves to configured GOOGLE_DRIVE_FOLDER_ID.
        
        Args:
            filename: Name of the file being analyzed
            report_content: AI-generated analysis/optimization report text
        
        Returns:
            Dictionary with doc_url, doc_id, filename, or None if failed
        """
        doc_title = f"Code Optimization Report - {filename} ({datetime.now().strftime('%Y-%m-%d %H:%M')})"
        
        return self.create_optimization_doc(
            title=doc_title,
            content=report_content,
            folder_id=GOOGLE_DRIVE_FOLDER_ID  # Explicit folder targeting
        )
    
    def resolve_drive_folder_id(self, drive_service, source_doc_id):
        """Resolve a folder ID by reading the parent of a known document."""
        if not source_doc_id:
            return None
        try:
            file_info = drive_service.files().get(
                fileId=source_doc_id,
                fields="parents"
            ).execute()
            parents = file_info.get("parents", [])
            folder_id = parents[0] if parents else None
            if folder_id:
                logger.info(f"‚úì Resolved Drive folder ID from source doc: {folder_id}")
            return folder_id
        except Exception as e:
            logger.warning(f"Could not resolve Drive folder ID from source doc: {e}")
            return None
    
    def create_optimization_doc(self, title, content, folder_id=None):
        """
        Create a new Google Doc with optimization analysis or code review.
        Uses Google Docs API to create and write content.
        
        Args:
            title: Title of the document
            content: The text/analysis to write to the document
            folder_id: Optional Google Drive folder ID (uses config value if not provided)
        
        Returns:
            Dictionary with document URL and ID, or None if failed
        """
        try:
            if folder_id is None:
                folder_id = GOOGLE_DRIVE_FOLDER_ID
            
            # Get Google API credentials
            creds = get_google_creds()
            
            if not creds:
                logger.error("Failed to get Google credentials for Docs API")
                return None
            
            # Create Docs service
            docs_service = build('docs', 'v1', credentials=creds)
            drive_service = build('drive', 'v3', credentials=creds)
            
            resolved_folder_id = folder_id
            if not resolved_folder_id and GOOGLE_DRIVE_FOLDER_SOURCE_DOC_ID:
                resolved_folder_id = self.resolve_drive_folder_id(
                    drive_service,
                    GOOGLE_DRIVE_FOLDER_SOURCE_DOC_ID
                )
            
            # Create a new document
            doc_body = {
                'title': title
            }
            
            logger.info(f"Creating Google Doc: {title}")
            doc = docs_service.documents().create(body=doc_body).execute()
            doc_id = doc.get('documentId')
            doc_url = f"https://docs.google.com/document/d/{doc_id}/edit"
            
            logger.info(f"‚úì Document created: {doc_url}")
            
            # Write content to the document
            if not content:
                content = "(No content provided)"

            # Docs API requires an insertion location
            requests_body = {
                'requests': [
                    {
                        'insertText': {
                            'location': {'index': 1},
                            'text': content
                        }
                    }
                ]
            }
            
            # Execute the writing request
            docs_service.documents().batchUpdate(
                documentId=doc_id,
                body=requests_body
            ).execute()
            
            logger.info(f"‚úì Content written to document ({len(content)} bytes)")
            
            # Move document to specified folder if provided
            if resolved_folder_id:
                try:
                    previous_parents = ",".join(
                        drive_service.files().get(
                            fileId=doc_id,
                            fields='parents'
                        ).execute().get('parents', [])
                    )
                    
                    drive_service.files().update(
                        fileId=doc_id,
                        addParents=resolved_folder_id,
                        removeParents=previous_parents,
                        fields='id, parents'
                    ).execute()
                    
                    logger.info(f"‚úì Document moved to folder: {resolved_folder_id}")
                except HttpError as e:
                    status = getattr(e.resp, "status", None)
                    if status == 404 and GOOGLE_DRIVE_FOLDER_SOURCE_DOC_ID:
                        fallback_id = self.resolve_drive_folder_id(
                            drive_service,
                            GOOGLE_DRIVE_FOLDER_SOURCE_DOC_ID
                        )
                        if fallback_id and fallback_id != resolved_folder_id:
                            try:
                                drive_service.files().update(
                                    fileId=doc_id,
                                    addParents=fallback_id,
                                    removeParents=previous_parents,
                                    fields='id, parents'
                                ).execute()
                                resolved_folder_id = fallback_id
                                logger.info(f"‚úì Document moved to folder: {resolved_folder_id}")
                            except Exception as retry_error:
                                logger.warning(f"Could not move document to fallback folder: {retry_error}")
                        else:
                            logger.warning(f"Could not resolve fallback Drive folder ID: {e}")
                    else:
                        logger.warning(f"Could not move document to folder: {e}")
                except Exception as e:
                    logger.warning(f"Could not move document to folder: {e}")
            
            # Log this action to memory
            self.log_vault_action(
                action_type="doc_created",
                description=f"Created optimization report: {title}",
                metadata={
                    "doc_id": doc_id,
                    "doc_url": doc_url,
                    "title": title,
                    "content_size": len(content)
                }
            )
            
            return {
                'doc_id': doc_id,
                'doc_url': doc_url,
                'title': title,
                'folder_id': resolved_folder_id,
                'success': True
            }
            
        except Exception as e:
            logger.error(f"Error creating Google Doc: {e}", exc_info=True)
            self.log(f"‚ùå Error creating doc: {e}")
            return None
    
    def log_vault_action(self, action_type, description, metadata=None):
        """
        Log vault-related actions (file reads, doc creation, conversations) to indexed memory.
        Unlimited storage with fast indexed search.
        
        Args:
            action_type: Type of action ('file_read', 'doc_created', 'conversation', etc.)
            description: Human-readable description of the action
            metadata: Optional dictionary with additional details
        """
        try:
            # Add to indexed memory system (no limits)
            self.memory_index.add_action(
                action_type=action_type,
                description=description,
                metadata=metadata
            )
            
            # Save to disk
            self.save_memory()
            
            logger.info(f"Vault action logged: {action_type} - {description}")
            
        except Exception as e:
            logger.error(f"Error logging vault action: {e}")
    
    def handle_report_retrieval(self, user_request):
        """
        Retrieve and summarize the last optimization report from memory.
        Uses indexed search for fast retrieval.
        """
        try:
            # Search indexed memory for last doc_created action
            recent_docs = self.memory_index.search_by_type('doc_created', limit=1)
            
            if not recent_docs:
                self.log("‚ùå No optimization reports found in memory.")
                self.speak_with_piper("I don't have any saved optimization reports in my memory yet.")
                return
            
            last_report = recent_docs[0]
            
            # Extract report details
            metadata = last_report.get('metadata', {})
            doc_id = metadata.get('doc_id')
            doc_url = metadata.get('doc_url', 'Unknown')
            doc_title = metadata.get('title', 'Unknown Report')
            timestamp = last_report.get('timestamp', 'Unknown time')
            
            # Display report info
            self.log(f"üìÑ Last Report: {doc_title}")
            self.log(f"üïí Created: {timestamp}")
            self.log(f"üîó URL: {doc_url}")
            
            # Read the document content from Google Docs
            self.log("üìñ Reading document content...")
            self.speak_with_piper("Reading the optimization report now.")
            
            creds = get_google_creds()
            if not creds or not doc_id:
                self.log("‚ùå Could not access document")
                self.speak_with_piper("I couldn't access the document.")
                return
            
            docs_service = build('docs', 'v1', credentials=creds)
            doc = docs_service.documents().get(documentId=doc_id).execute()
            
            # Extract text content from the document
            doc_content = ""
            for element in doc.get('body', {}).get('content', []):
                if 'paragraph' in element:
                    for text_run in element['paragraph'].get('elements', []):
                        if 'textRun' in text_run:
                            doc_content += text_run['textRun'].get('content', '')
            
            self.log(f"‚úì Read {len(doc_content)} characters from document")
            
            # Check gaming mode - skip AI processing
            if self.gaming_mode:
                self.log("‚ö†Ô∏è  Gaming Mode active - AI brain disabled")
                self.speak_with_piper("Gaming mode is enabled, AI processing is disabled.")
                return
            
            # Send to brain for summarization
            self.log("üß† Analyzing report for summary...")
            self.speak_with_piper("Analyzing the report for you.")
            
            summary_prompt = f"""Provide a concise 3-point executive summary of this code optimization report:

{doc_content}

Format your response as:
1. [First key finding]
2. [Second key finding]
3. [Third key finding]

Keep it brief and actionable."""
            
            response = requests.post(
                BRAIN_URL,
                json={
                    "model": LLM_MODEL,
                    "prompt": summary_prompt,
                    "stream": False
                },
                timeout=60
            )
            
            summary = response.json().get('response', 'Could not generate summary.')
            
            # Display and speak the summary
            self.log("\nüìä SUMMARY:")
            self.log(summary)
            self.speak_with_piper(f"Here's the summary: {summary}")

            # Display in focus panel
            if hasattr(self, 'dashboard'):
                panel_content = f"Summary:\n{summary}\n\n---\n\nFull Document (excerpt):\n{doc_content[:2000]}"
                self.dashboard.push_focus("docs", doc_title, panel_content)

            # Open in browser as well
            import webbrowser
            webbrowser.open(doc_url)
            self.log(f"‚úì Opened in browser: {doc_url}")
            
            # Log report retrieval action
            self.log_vault_action(
                action_type="report_retrieved",
                description=f"Retrieved and summarized: {doc_title}",
                metadata={
                    "doc_id": doc_id,
                    "doc_url": doc_url,
                    "doc_title": doc_title,
                    "original_timestamp": timestamp,
                    "summary_length": len(summary)
                }
            )
            
        except Exception as e:
            logger.error(f"Error retrieving report: {e}", exc_info=True)
            self.log(f"‚ùå Error retrieving report: {e}")
            self.speak_with_piper("I encountered an error retrieving the report.")
    
    def get_calendar(self):
        """Get upcoming calendar events using Google Calendar API (real data)."""
        try:
            creds = get_google_creds()
            if hasattr(self, 'dashboard'):
                panel_content = f"Summary:\n{summary}\n\n---\n\nFull Document (excerpt):\n{doc_content[:2000]}"
                self.dashboard.push_focus("docs", doc_title, panel_content)

            # Open in browser as well
            import webbrowser
            webbrowser.open(doc_url)
            self.log(f"‚úì Opened in browser: {doc_url}")
            
            # Log report retrieval action
            self.log_vault_action(
                action_type="report_retrieved",
                description=f"Retrieved and summarized: {doc_title}",
                metadata={
                    "doc_id": doc_id,
                    "doc_url": doc_url,
                    "doc_title": doc_title,
                    "original_timestamp": timestamp,
                    "summary_length": len(summary)
                }
            )
            
        except Exception as e:
            logger.error(f"Error retrieving report: {e}", exc_info=True)
            self.log(f"‚ùå Error retrieving report: {e}")
            self.speak_with_piper("I encountered an error retrieving the report.")
    
    def perplexity_search(self, query):
        """Perform a web search using the Perplexity API for more accurate, conversational results."""
        if not PERPLEXITY_API_KEY:
            logger.error("Perplexity API key is not configured. Falling back to Google Search.")
            return self.google_search(query)

        try:
            headers = {
                "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
                "Content-Type": "application/json"
            }
            payload = {
                "model": "sonar-medium-online",
                "messages": [
                {"role": "system", "content": "You are a helpful research assistant. Provide a detailed, well-structured answer to the user's query, using markdown for headings, lists, and hyperlinks where appropriate."},
                    {"role": "user", "content": query}
                ]
            }
            
            response = requests.post("https://api.perplexity.ai/chat/completions", headers=headers, json=payload, timeout=30)
            response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)

            data = response.json()
            answer = data.get('choices', [{}])[0].get('message', {}).get('content', '')
            
            logger.info(f"‚úì Perplexity search for '{query}' successful.")
            return answer if answer else ""

        except Exception as e:
            logger.error(f"Perplexity search failed for query '{query}': {e}", exc_info=True)
            return f"An unexpected error occurred during the Perplexity search: {e}"

    def handle_web_search(self, user_request):
        """
        Perform a web search, display results with short-keys, and populate session context.
        """
        # Extract query from user request (e.g., "search for python tutorials")
        query_match = re.search(r'(?:search for|search|who is|what is|find|google)\s+(.+)', user_request, re.IGNORECASE)
        query = query_match.group(1) if query_match else user_request

        self.log(f"üîç Searching the web for: {query}")
        self.speak_with_piper(f"Searching for {query}.")
        self.status_var.set("Status: Searching...")

        # Use Google Search which returns a list of items
        search_results = self.google_search(query)

        if not search_results:
            self.log("‚ùå No web results found.")
            self.speak_with_piper("I couldn't find anything for that search, sir.")
            return

        self.log(f"‚úì Found {len(search_results)} web results.")

        # --- NEW: Populate Context and UI ---
        focus_content = f"Web Search Results for '{query}':\n\n"
        ticker_items = []

        for item in search_results:
            title = item.get('title', 'No Title')
            snippet = item.get('snippet', 'No snippet available.')
            url = item.get('link', '')

            # 1. Create a persistent ledger entry and get a key
            ledger_entry = self.conversational_ledger.add_entry(
                item_type='w',
                description=f"Web search result: {title}",
                metadata={'url': url, 'query': query, 'snippet': snippet}
            )
            full_key = ledger_entry['metadata']['short_key']
            short_alias = full_key.split('-')[-1]

            # 2. Add to volatile session context for immediate follow-up
            self.session_context.add_item(
                full_key=full_key,
                label=title.split('|')[0].strip(), # Use text before first pipe for ticker
                item_type='w',
                metadata={'url': url, 'title': title}
            )

            # 3. Format for Focus Panel
            focus_content += f"[{short_alias}] {title}\n"
            focus_content += f"    {snippet.replace(chr(10), ' ')}\n\n"

            # 4. Add to ticker list
            ticker_items.append({"short_key": short_alias, "label": title})

        # 5. Push updates to Dashboard
        self.dashboard.push_focus("docs", f"Web Search: {query}", focus_content)
        self.dashboard.update_ticker(self.session_context.get_all_items_for_ticker())

        # 6. Confirm with user
        self.speak_with_piper(f"Sir, I've found {len(search_results)} results. They are on screen.")
        self.last_intent = "search"

    def handle_email_summary_request(self):
        """
        Summarize recent emails from Gmail, display with short-keys, and populate context.
        """
        try:
            logger.info("Fetching recent emails from Gmail...")
            gmail_emails = self.get_recent_emails(limit=5)

            if not gmail_emails:
                self.log("‚ùå No recent emails found")
                self.speak_with_piper("You don't have any recent emails.")
                return

            self.log(f"üìß Found {len(gmail_emails)} recent email(s) in Gmail")
            self.last_intent = "email"
            self.last_email_context = gmail_emails[0] # For legacy context

            # --- NEW: Populate Context and UI ---
            focus_content = "Recent Emails:\n\n"
            email_text_for_summary = ""

            for i, email in enumerate(gmail_emails, 1):
                sender_name = self.extract_sender_name(email['sender'])
                subject = email.get('subject', 'No Subject')

                # 1. Create ledger entry
                ledger_entry = self.conversational_ledger.add_entry(
                    item_type='e',
                    description=f"Recent email from {sender_name}: {subject}",
                    metadata={'id': email['id'], 'sender': email['sender'], 'subject': subject}
                )
                full_key = ledger_entry['metadata']['short_key']
                short_alias = full_key.split('-')[-1]

                # 2. Add to session context
                self.session_context.add_item(
                    full_key=full_key,
                    label=sender_name.split(' ')[0],
                    item_type='e',
                    metadata={'id': email['id'], 'sender': email['sender'], 'subject': subject}
                )

                # 3. Format for Focus Panel
                focus_content += (
                    f"[{short_alias}] {subject}\n"
                    f"    From: {sender_name}\n"
                    f"    Snippet: {email['snippet']}\n\n"
                )
                
                # 4. Format for LLM summary
                email_text_for_summary += f"{i}. From: {sender_name}\n   Subject: {subject}\n   Preview: {email['snippet'][:150]}\n\n"

            # Push list to dashboard first
            self.dashboard.push_focus("email", "Recent Emails", focus_content)
            self.dashboard.update_ticker(self.session_context.get_all_items_for_ticker())
            self.speak_with_piper("Here are your most recent emails.")

            # Now, generate and speak the summary as a secondary action
            if self.gaming_mode:
                self.log("‚ö†Ô∏è  Gaming Mode active - AI brain disabled")
                return

            self.log("üß† Generating AI summary...")
            self.speak_with_piper("I'll give you a summary.")

            summary_prompt = f"""Provide a brief executive summary of these emails in 2-3 sentences.
Focus on important senders and key topics.

{email_text_for_summary}

Summary (concise, action-item focused):"""

            response = requests.post(
                BRAIN_URL,
                json={"model": LLM_MODEL, "prompt": summary_prompt, "stream": False},
                timeout=60
            )
            summary = response.json().get('response', 'Could not generate summary.')

            self.log(f"\nüìß SUMMARY: {summary}")
            self.speak_with_piper(summary)

            # Log action
            self.log_vault_action(
                action_type="email_summarized",
                description="Summarized recent emails",
                metadata={"email_count": len(gmail_emails), "summary_length": len(summary)}
            )

        except Exception as e:
            logger.error(f"Error summarizing emails: {e}", exc_info=True)
            self.log(f"‚ùå Error summarizing emails: {e}")
            self.speak_with_piper("I encountered an error summarizing your emails.")
    
    def handle_email_search_request(self, user_request):
        """
        Search Gmail, display results with short-keys, and populate session context.
        """
        try:
            text_lower = user_request.lower()
            
            # Extract sender name/email from request
            # Patterns: "from [name/email]", "from: [name/email]", "[name/email]"
            import re
            
            # Try to extract email pattern
            email_match = re.search(r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', user_request)
            sender_query = email_match.group(1) if email_match else None
            
            # Try to extract name after "from"
            if not sender_query:
                from_match = re.search(r'from\s+([a-zA-Z\s]+?)(?:\s+about|\s+regarding|\s+subject|$)', user_request, re.IGNORECASE)
                if from_match:
                    sender_query = from_match.group(1).strip()
            
            if not sender_query:
                self.log("‚ùå Could not identify who to search for")
                self.speak_with_piper("Could you please specify whose emails you'd like me to search for?")
                return
            
            # Build Gmail search query
            gmail_query = f"from:{sender_query}"
            
            # Check for subject keywords too
            subject_match = re.search(r'(?:about|regarding|subject:)\s+([a-zA-Z\s]+?)(?:$|\s+before|\s+since)', user_request, re.IGNORECASE)
            if subject_match:
                subject = subject_match.group(1).strip()
                gmail_query += f" subject:{subject}"
            
            logger.info(f"Gmail search query: {gmail_query}")
            self.log(f"üîç Searching Gmail for: {sender_query}")
            self.status_var.set("Status: Searching Gmail...")
            
            # Perform Gmail search
            emails = self.search_emails(gmail_query)
            
            if not emails:
                self.log(f"‚ùå No emails found from {sender_query}")
                self.speak_with_piper(f"I didn't find any emails from {sender_query}.")
                return

            self.log(f"‚úì Found {len(emails)} email(s)")
            self.last_intent = "email"
            self.last_email_context = emails[0] # For legacy context

            # --- NEW: Populate Context and UI ---
            focus_content = f"Found {len(emails)} emails matching your search for '{sender_query}':\n\n"

            for email in emails:
                sender_name = self.extract_sender_name(email['sender'])
                subject = email.get('subject', 'No Subject')
                
                # 1. Create ledger entry
                ledger_entry = self.conversational_ledger.add_entry(
                    item_type='e',
                    description=f"Email from {sender_name}: {subject}",
                    metadata={'id': email['id'], 'sender': email['sender'], 'subject': subject}
                )
                full_key = ledger_entry['metadata']['short_key']
                short_alias = full_key.split('-')[-1]

                # 2. Add to session context
                self.session_context.add_item(
                    full_key=full_key,
                    label=sender_name.split(' ')[0], # First name for ticker
                    item_type='e',
                    metadata={'id': email['id'], 'sender': email['sender']}
                )

                # 3. Format for Focus Panel
                focus_content += (
                    f"[{short_alias}] {subject}\n"
                    f"    From: {sender_name}\n"
                    f"    Snippet: {email['snippet']}\n\n"
                )

            # 5. Push updates to Dashboard
            self.dashboard.push_focus(
                content_type="email",
                title=f"Email Search: {sender_query}",
                content=focus_content
            )
            self.dashboard.update_ticker(self.session_context.get_all_items_for_ticker())

            # 6. Speak confirmation
            summary = f"I found {len(emails)} email(s) from {sender_query}. They are now on screen."
            self.speak_with_piper(summary)
            
            # Log action
            self.log_vault_action(
                action_type="email_searched",
                description=f"Searched emails from: {sender_query}",
                metadata={
                    "search_query": gmail_query,
                    "results_count": len(emails),
                    "timestamp": datetime.now().isoformat()
                }
            )
            
        except Exception as e:
            logger.error(f"Error searching emails: {e}", exc_info=True)
            self.log(f"‚ùå Email search failed: {e}")
            self.speak_with_piper("I encountered an error searching your emails.")
    
    def call_smart_model(self, prompt: str, timeout: int = 120) -> str:
        """Route to GPT-4o when the OpenAI key is available, fall back to Ollama.

        Used for tasks that require deep reasoning (code analysis, etc.) where
        the local llama3.1:8b model hallucinates or gives generic advice.
        """
        openai_key = os.getenv("OPENAI_API_KEY", "")
        if openai_key:
            try:
                from openai import OpenAI
                client = OpenAI(api_key=openai_key)
                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=2000,
                    timeout=timeout
                )
                logger.info("Smart model: used GPT-4o")
                return response.choices[0].message.content or ""
            except Exception as e:
                logger.warning(f"GPT-4o unavailable, falling back to Ollama: {e}")
        # Fallback ‚Äî local Ollama
        resp = requests.post(
            BRAIN_URL,
            json={"model": LLM_MODEL, "prompt": prompt, "stream": False},
            timeout=timeout
        )
        logger.info("Smart model: used Ollama (fallback)")
        return resp.json().get('response', 'Analysis could not be completed.')

    def handle_optimization_request(self, user_request):
        """
        Multi-step intent handler for code analysis and documentation workflow.
        Refactored to use the Visual Addressing system.
        """
        try:
            self.status_var.set("Status: üîß Analyzing code...")
            
            # Step 1: Extract which file the user wants to analyze
            text_lower = user_request.lower()
            
            # Try to determine which file to analyze
            target_file = None
            
            # Look for specific file references
            if "main" in text_lower:
                target_file = self.vault.get_file('main')
            elif "startup" in text_lower:
                target_file = self.vault.get_file('startup')
            elif "config" in text_lower:
                target_file = self.vault.get_file('config')
            elif "ear" in text_lower:
                target_file = self.vault.get_file('ear')
            else:
                # Try to extract filename from request
                # Look for patterns like "check [filename]"
                import re
                file_match = re.search(r'(?:check|analyze|optimise|read)\s+(?:the\s+)?(?:file\s+)?([a-zA-Z_]\w*\.py)', text_lower)
                if file_match:
                    filename = file_match.group(1)
                    target_file = self.vault.search_file(filename)
            
            if not target_file:
                self.log("‚ùå Could not identify which file to analyze. Please specify a file name.")
                self.speak_with_piper("I couldn't identify which file you'd like me to analyze. Please be more specific.")
                return
            
            # Log action
            self.log_vault_action(
                action_type="optimization_start",
                description=f"Starting optimization analysis for {os.path.basename(target_file)}"
            )
            
            # Step 2: Read the file content
            self.log(f"üìñ Reading: {os.path.basename(target_file)}")
            self.speak_with_piper("Reading the file now.")
            
            file_data = self.get_file_content(os.path.basename(target_file))
            
            if not file_data or not file_data.get('content'):
                self.log(f"‚ùå Could not read file: {target_file}")
                self.speak_with_piper("I had trouble reading the file. Please check it exists.")
                return
            
            file_content = file_data['content']
            filename = file_data['filename']
            
            # Check gaming mode - skip AI processing
            if self.gaming_mode:
                self.log("‚ö†Ô∏è  Gaming Mode active - AI brain disabled")
                self.speak_with_piper("Gaming mode is enabled, code optimization is disabled.")
                return
            
            # Step 3: Send to Ollama/Brain for optimization analysis
            self.log("üß† Sending to AI brain for analysis...")
            self.speak_with_piper("Analyzing the code for optimization opportunities.")
            
            optimization_prompt = f"""You are an expert code reviewer analysing a specific codebase.

ARCHITECTURE (read carefully before analysing):
- This is a headless Python voice assistant ‚Äî no GUI, no web framework serving users.
- NO SQL database, no SQLAlchemy, no db_session, no User/Conversation ORM models.
- Conversation state is held in self.context_buffer (a Python list already in RAM).
- Persistent memory is jarvis_memory.json ‚Äî loaded once at startup, saved periodically.
- Flask runs in a single daemon background thread solely to receive n8n webhooks on port 5001.
- Background tasks use threading.Thread(daemon=True) ‚Äî no thread pool is needed or appropriate.
- There is nothing to cache ‚Äî all runtime state is already in memory.
DO NOT suggest: databases, SQLAlchemy, ThreadPoolExecutor for Flask.run(), or caching layers.

FILE TO ANALYSE: {filename}

CODE:
{file_content}

Identify the THREE most important real improvements specific to THIS codebase. For each:
1. Issue: Describe the actual problem found in this file
2. Impact: What concrete benefit would this provide?
3. Suggestion: Show a specific code change (not a generic pattern)

Plain text only ‚Äî no markdown, no bullet symbols, no code fences."""

            self.status_var.set("Status: üß† AI Analysis in Progress...")
            optimization_analysis = self.call_smart_model(optimization_prompt, timeout=120)
            self.log("‚úì Analysis complete")
            
            # Step 4: Create Google Doc with the analysis (Scribe Workflow)
            self.log("üìù Creating Google Doc...")
            self.speak_with_piper("Creating your optimization report document.")
            
            doc_result = self.write_optimization_to_doc(
                filename=filename,
                report_content=optimization_analysis
            )
            
            if not doc_result or not doc_result.get('success'):
                self.log("‚ùå Failed to create Google Doc")
                self.speak_with_piper("I encountered an error creating the document.")
                return
            
            # --- NEW: Integrate with Visual Addressing ---
            ledger_entry = self.conversational_ledger.add_entry(
                item_type='c', # 'c' for code/vault analysis
                description=f"Code analysis for {filename}",
                metadata={
                    'doc_id': doc_result.get('doc_id'),
                    'doc_url': doc_result.get('doc_url'),
                    'source_file': filename,
                    'summary': optimization_analysis
                }
            )
            new_full_key = ledger_entry['metadata']['short_key']
            new_short_alias = new_full_key.split('-')[-1]

            self.session_context.add_item(
                full_key=new_full_key,
                label=f"Analysis: {filename}",
                item_type='c',
                metadata={
                    'doc_url': doc_result.get('doc_url'),
                    'summary': optimization_analysis
                }
            )

            doc_title = doc_result.get('title', 'Optimization Report')
            preview = optimization_analysis[:3000]
            if len(optimization_analysis) > 3000:
                preview += "\n\n[... truncated ‚Äî see Google Doc for full report]"
            
            focus_title = f"[{new_short_alias}] {doc_title}"
            self.dashboard.push_focus("code", focus_title, preview)
            self.dashboard.update_ticker(self.session_context.get_all_items_for_ticker())

            confirmation = f"Sir, the optimization report for {filename} is ready. It is referenced as {new_short_alias}."
            self.speak_with_piper(confirmation)
            self.log(f"üîä Confirmed: {confirmation}")
            
            self.last_intent = "optimization"
            self.save_memory()
            
            if hasattr(self, 'dashboard'):
                self.dashboard.push_state(mode="idle")

            logger.info(f"‚úì Optimization workflow complete for {filename}")
            self.status_var.set("Status: Ready")
            
        except Exception as e:
            error_msg = f"Error in optimization workflow: {e}"
            logger.error(error_msg, exc_info=True)
            self.log(f"‚ùå {error_msg}")
            self.speak_with_piper("An error occurred during the analysis. Please check the console for details.")
    
    def _handle_contextual_command(self, raw_text: str) -> bool:
        """
        Contextual Resolver: Handles commands targeting a short-key (e.g., "open wr1").
        Returns True if a command was found and handled, False otherwise.
        """
        # Regex to find an action and a short-key alias, plus any trailing text for replies
        match = re.search(
            r'^(?:open|show|display|summarise|summarize|analyse|analyze|reply to|dig deeper into|go to|archive|delete)\s+([ewdchq]r?\d+.*)$',
            raw_text.lower().strip()
        )

        if not match:
            return False

        action_verb = match.group(0).split(' ')[0]
        full_target = match.group(1)
        
        # Extract short_alias and potential trailing text (for replies)
        target_match = re.match(r'([ewdchq]r?\d+)', full_target)
        if not target_match: return False
        short_alias = target_match.group(1)
        
        item = self.session_context.get_item(short_alias)

        if not item:
            logger.warning(f"Contextual command for '{short_alias}' but item not in session context.")
            return False

        logger.info(f"Contextual command resolved: '{raw_text}' -> item '{short_alias}'")
        item_type = item.get('type')
        metadata = item.get('metadata', {})

        # --- Delegate to appropriate handler based on type ---

        if 'dig' in action_verb and item_type == 'w':
            self.handle_deep_dig(item)
            return True

        if item_type == 'w':  # Web Result
            url = metadata.get('url')
            if url and action_verb in ['open', 'go']:
                self.log(f"Opening web result {short_alias}: {url}")
                import webbrowser
                webbrowser.open(url)
                self.speak_with_piper(f"Opening {item.get('label', 'that link')}.")
                return True

        elif item_type == 'e':  # Email
            email_id = metadata.get('id')
            if not email_id: return False

            if 'reply' in action_verb:
                reply_match = re.search(r'saying\s+(.+)', raw_text, re.IGNORECASE)
                reply_text = reply_match.group(1) if reply_match else ""
                if not reply_text:
                    self.speak_with_piper("What would you like to say in the reply?")
                    return True
                
                self.pending_reply = {
                    'email_id': email_id, 'sender': metadata.get('sender'),
                    'sender_name': item.get('label'), 'reply_text': reply_text
                }
                self.speak_with_piper(f"Just to confirm ‚Äî shall I send that reply to {item.get('label')}?")
                self.dashboard.push_focus("email", "Pending Reply", f"To: {metadata.get('sender')}\n\nMessage:\n{reply_text}")
                return True

            elif action_verb in ['archive', 'delete']:
                tool = self.archive_email if action_verb == 'archive' else self.trash_email
                if tool(email_id):
                    self.speak_with_piper(f"Done. I've {action_verb}d email {short_alias}.")
                else:
                    self.speak_with_piper(f"I had trouble {action_verb}ing that email.")
                return True

            elif action_verb in ['show', 'display', 'open']:
                self.speak_with_piper(f"Bringing up email {short_alias} from {item.get('label')}.")
                email_body = self.get_email_body(email_id)
                focus_title = f"[{short_alias}] Email from: {item.get('label')}"
                focus_content = f"Subject: {metadata.get('subject', 'N/A')}\n\n---\n\n{email_body}"
                self.dashboard.push_focus("email", focus_title, focus_content)
                return True

        elif item_type in ['d', 'c']:  # Document or Code Analysis
            if action_verb in ['show', 'display', 'open']:
                self.speak_with_piper(f"Displaying the analysis for {short_alias}.")
                self.dashboard.push_focus(
                    "docs" if item_type == 'd' else "code",
                    f"[{short_alias}] {item.get('label')}",
                    metadata.get('summary', 'No summary available.')
                )
                return True
            elif 'summarize' in action_verb or 'summarise' in action_verb:
                self.speak_with_piper(f"Summarizing {short_alias}.")
                summary_prompt = f"Provide a concise 3-point executive summary of this document:\n\n{metadata.get('summary')}"
                summary = self.call_smart_model(summary_prompt)
                self.speak_with_piper(f"Here is the summary: {summary}")
                self.dashboard.push_focus(
                    "docs" if item_type == 'd' else "code",
                    f"Summary of {short_alias}: {item.get('label')}",
                    summary
                )
                return True

        self.speak_with_piper(f"I'm not sure how to handle that action for {short_alias} yet.")
        return True

    def process_conversation(self, raw_text):
        """The main entry point for processing a user's voice command."""
        logger.debug(f"Processing conversation: {raw_text}")
        self.log(f"User: {raw_text}")

        try:
            # ‚îÄ‚îÄ STEP 1: Pending confirmations (e.g., "send email?") ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if self.check_pending_confirmation(raw_text):
                return

            # --- NEW: Step 2: Contextual Command Resolution (e.g., "summarize wr1") ---
            if self._handle_contextual_command(raw_text):
                return

            # --- If not a contextual command, it's a new query. Clear the session. ---
            self.session_context.clear()
            if hasattr(self, 'dashboard'):
                self.dashboard.update_ticker([]) # Clear the ticker tape

            # ‚îÄ‚îÄ STEP 3: Legacy Context-aware follow-ups (e.g., "archive that") ‚îÄ‚îÄ
            if self._route_by_context(raw_text, raw_text.lower()):
                return

            # ‚îÄ‚îÄ STEP 4: Score and route to the best intent handler ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            intent, score, details = self.route_intent(raw_text)

            if intent == "AMBIGUOUS":
                self.ask_for_clarification(raw_text, details['ambiguous_intents'])
            elif intent and intent != "LLM_BRAIN":
                handler = getattr(self, INTENTS[intent]['handler'])
                handler(raw_text)
            else:
                # ‚îÄ‚îÄ STEP 5: Fallback to general-purpose LLM brain ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                self.fallback_to_llm(raw_text)
        finally:
            # This block runs before any `return` in the `try` block,
            # and also if the `try` block completes normally, ensuring the
            # queue is always processed after an interaction.
            self.process_notification_queue(context="busy")
            self.last_interaction_time = time.time()
            logger.debug("Conversation processed successfully")

    def google_search(self, query):
        """Perform Google search using Custom Search API with API key."""
        try:
            if not GOOGLE_CSE_API_KEY or not GOOGLE_CSE_CX:
                logger.error("Google Search API key or CX is not configured.")
                return "Search is not configured. The API key is missing."

            service = build("customsearch", "v1", developerKey=GOOGLE_CSE_API_KEY)
            res = service.cse().list(q=query, cx=GOOGLE_CSE_CX, num=3).execute()
            items = res.get('items', [])

            if not items:
                logger.warning(f"Google Custom Search for '{query}' returned 0 items. The CSE might be misconfigured for general web searches.")
                return []  # Return empty list for no results

            # Return structured data instead of a formatted string
            return items
        except HttpError as e:
            error_details = json.loads(e.content).get('error', {})
            message = error_details.get('message', str(e))
            logger.error(f"Google Search API HTTP error for query '{query}': {message}")
            return []
        except Exception as e:
            logger.error(f"Google Search failed for query '{query}': {e}", exc_info=True)
            return []

    def get_calendar(self):
        """Get upcoming calendar events using Google Calendar API (real data)."""
        try:
            creds = get_google_creds()
            if hasattr(self, 'dashboard'):
                panel_content = f"Summary:\n{summary}\n\n---\n\nFull Document (excerpt):\n{doc_content[:2000]}"
                self.dashboard.push_focus("docs", doc_title, panel_content)

            # Open in browser as well
            import webbrowser
            webbrowser.open(doc_url)
            self.log(f"‚úì Opened in browser: {doc_url}")
            
            # Log report retrieval action
            self.log_vault_action(
                action_type="report_retrieved",
                description=f"Retrieved and summarized: {doc_title}",
                metadata={
                    "doc_id": doc_id,
                    "doc_url": doc_url,
                    "doc_title": doc_title,
                    "original_timestamp": timestamp,
                    "summary_length": len(summary)
                }
            )
            
        except Exception as e:
            logger.error(f"Error retrieving report: {e}", exc_info=True)
            self.log(f"‚ùå Error retrieving report: {e}")
            self.speak_with_piper("I encountered an error retrieving the report.")
    
    def perplexity_search(self, query):
        """Perform a web search using the Perplexity API for more accurate, conversational results."""
        if not PERPLEXITY_API_KEY:
            logger.error("Perplexity API key is not configured. Falling back to Google Search.")
            return self.google_search(query)

        try:
            headers = {
                "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
                "Content-Type": "application/json"
            }
            payload = {
                "model": "sonar-medium-online",
                "messages": [
                {"role": "system", "content": "You are a helpful research assistant. Provide a detailed, well-structured answer to the user's query, using markdown for headings, lists, and hyperlinks where appropriate."},
                    {"role": "user", "content": query}
                ]
            }
            
            response = requests.post("https://api.perplexity.ai/chat/completions", headers=headers, json=payload, timeout=30)
            response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)

            data = response.json()
            answer = data.get('choices', [{}])[0].get('message', {}).get('content', '')
            
            logger.info(f"‚úì Perplexity search for '{query}' successful.")
            return answer if answer else ""

        except Exception as e:
            logger.error(f"Perplexity search failed for query '{query}': {e}", exc_info=True)
            return f"An unexpected error occurred during the Perplexity search: {e}"

    def handle_deep_dig(self, item: dict):
        """
        Performs a "deep dig" on a web result item by scraping its URL
        and generating a new summary document.
        """
        if not BS4_AVAILABLE:
            self.log("‚ùå BeautifulSoup4 not installed. Cannot perform deep dig.")
            self.speak_with_piper("I'm sorry, the web scraping tool is not installed.")
            return

        short_alias = item['full_key'].split('-')[-1]
        url = item.get('metadata', {}).get('url')
        label = item.get('label', 'that web result')

        if not url:
            self.log(f"‚ùå No URL found for item {short_alias}.")
            self.speak_with_piper(f"I'm sorry, I don't have a URL for {short_alias}.")
            return

        self.log(f"üïµÔ∏è‚Äç‚ôÇÔ∏è Digging deeper into {short_alias}: {url}")
        self.speak_with_piper(f"Digging deeper into {label}.")
        self.status_var.set(f"Status: Scraping {short_alias}...")

        try:
            # 1. Scrape the web page
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
            response = requests.get(url, timeout=15, headers=headers)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Extract meaningful text, removing script/style tags
            for script_or_style in soup(["script", "style"]):
                script_or_style.decompose()
            
            page_text = ' '.join(soup.stripped_strings)
            
            if not page_text:
                self.log(f"‚ùå No text content could be extracted from {url}.")
                self.speak_with_piper("I was unable to extract any readable content from that page.")
                return

            self.log(f"‚úì Scraped {len(page_text)} characters from {short_alias}.")
            self.status_var.set(f"Status: Analyzing content...")

            # 2. Send to LLM for summarization
            summary_prompt = f"""Please provide a detailed, structured summary of the following web page content. 
Focus on the key arguments, data, and conclusions. Use markdown for structure if appropriate.

CONTENT:
{page_text[:8000]} 

SUMMARY:""" # Limit context to avoid huge payloads

            summary = self.call_smart_model(summary_prompt, timeout=120)

            if not summary:
                self.log("‚ùå AI analysis failed to produce a summary.")
                self.speak_with_piper("The analysis did not return a result.")
                return

            # 3. Create a new ledger entry and session item for the document
            ledger_entry = self.conversational_ledger.add_entry(
                item_type='d',
                description=f"Deep-dig analysis of '{label}'",
                metadata={'source_url': url, 'source_key': item['full_key'], 'summary': summary}
            )
            new_full_key = ledger_entry['metadata']['short_key']
            new_short_alias = new_full_key.split('-')[-1]

            self.session_context.add_item(
                full_key=new_full_key,
                label=f"Analysis: {label}",
                item_type='d',
                metadata={'source_url': url, 'summary': summary}
            )

            # 4. Display on dashboard
            focus_title = f"Analysis of {short_alias}: {label}"
            focus_content = f"Source URL: {url}\n\n---\n\n{summary}"
            
            self.dashboard.push_focus("docs", focus_title, focus_content)
            self.dashboard.update_ticker(self.session_context.get_all_items_for_ticker())

            # 5. Confirm with user
            self.speak_with_piper(f"Sir, my analysis of {label} is complete and on screen. It is now referenced as {new_short_alias}.")
            self.last_intent = "document_analysis" # New intent type for context

        except requests.RequestException as e:
            self.log(f"‚ùå Failed to fetch URL {url}: {e}")
            self.speak_with_piper("I was unable to access that web page.")
        except Exception as e:
            logger.error(f"Error during deep dig for {short_alias}: {e}", exc_info=True)
            self.log(f"‚ùå An unexpected error occurred during the analysis.")
            self.speak_with_piper("An unexpected error occurred during the analysis.")

    def handle_web_search(self, user_request):
        """
        Perform a web search, display results with short-keys, and populate session context.
        """
        # Extract query from user request (e.g., "search for python tutorials")
        query_match = re.search(r'(?:search for|search|who is|what is|find|google)\s+(.+)', user_request, re.IGNORECASE)
        query = query_match.group(1) if query_match else user_request

        self.log(f"üîç Searching the web for: {query}")
        self.speak_with_piper(f"Searching for {query}.")
        self.status_var.set("Status: Searching...")

        # Use Google Search which returns a list of items
        search_results = self.google_search(query)

        if not search_results:
            self.log("‚ùå No web results found.")
            self.speak_with_piper("I couldn't find anything for that search, sir.")
            return

        self.log(f"‚úì Found {len(search_results)} web results.")

        # --- NEW: Populate Context and UI ---
        focus_content = f"Web Search Results for '{query}':\n\n"
        ticker_items = []

        for item in search_results:
            title = item.get('title', 'No Title')
            snippet = item.get('snippet', 'No snippet available.')
            url = item.get('link', '')

            # 1. Create a persistent ledger entry and get a key
            ledger_entry = self.conversational_ledger.add_entry(
                item_type='w',
                description=f"Web search result: {title}",
                metadata={'url': url, 'query': query, 'snippet': snippet}
            )
            full_key = ledger_entry['metadata']['short_key']
            short_alias = full_key.split('-')[-1]

            # 2. Add to volatile session context for immediate follow-up
            self.session_context.add_item(
                full_key=full_key,
                label=title.split('|')[0].strip(), # Use text before first pipe for ticker
                item_type='w',
                metadata={'url': url}
            )

            # 3. Format for Focus Panel
            focus_content += f"[{short_alias}] {title}\n"
            focus_content += f"    {snippet.replace(chr(10), ' ')}\n\n"

            # 4. Add to ticker list
            ticker_items.append({"short_key": short_alias, "label": title})

        # 5. Push updates to Dashboard
        self.dashboard.push_focus("docs", f"Web Search: {query}", focus_content)
        self.dashboard.update_ticker(self.session_context.get_all_items_for_ticker())

        # 6. Confirm with user
        self.speak_with_piper(f"Sir, I've found {len(search_results)} results. They are on screen.")
        self.last_intent = "search"

    def handle_email_summary_request(self):
        """
        Summarize recent emails from Gmail, display with short-keys, and populate context.
        """
        try:
            logger.info("Fetching recent emails from Gmail...")
            gmail_emails = self.get_recent_emails(limit=5)

            if not gmail_emails:
                self.log("‚ùå No recent emails found")
                self.speak_with_piper("You don't have any recent emails.")
                return

            self.log(f"üìß Found {len(gmail_emails)} recent email(s) in Gmail")
            self.last_intent = "email"
            self.last_email_context = gmail_emails[0] # For legacy context

            # --- NEW: Populate Context and UI ---
            focus_content = "Recent Emails:\n\n"
            email_text_for_summary = ""

            for i, email in enumerate(gmail_emails, 1):
                sender_name = self.extract_sender_name(email['sender'])
                subject = email.get('subject', 'No Subject')

                # 1. Create ledger entry
                ledger_entry = self.conversational_ledger.add_entry(
                    item_type='e',
                    description=f"Recent email from {sender_name}: {subject}",
                    metadata={'id': email['id'], 'sender': email['sender'], 'subject': subject}
                )
                full_key = ledger_entry['metadata']['short_key']
                short_alias = full_key.split('-')[-1]

                # 2. Add to session context
                self.session_context.add_item(
                    full_key=full_key,
                    label=sender_name.split(' ')[0],
                    item_type='e',
                    metadata={'id': email['id'], 'sender': email['sender']}
                )

                # 3. Format for Focus Panel
                focus_content += (
                    f"[{short_alias}] {subject}\n"
                    f"    From: {sender_name}\n"
                    f"    Snippet: {email['snippet']}\n\n"
                )
                
                # 4. Format for LLM summary
                email_text_for_summary += f"{i}. From: {sender_name}\n   Subject: {subject}\n   Preview: {email['snippet'][:150]}\n\n"

            # Push list to dashboard first
            self.dashboard.push_focus("email", "Recent Emails", focus_content)
            self.dashboard.update_ticker(self.session_context.get_all_items_for_ticker())
            self.speak_with_piper("Here are your most recent emails.")

            # Now, generate and speak the summary as a secondary action
            if self.gaming_mode:
                self.log("‚ö†Ô∏è  Gaming Mode active - AI brain disabled")
                return

            self.log("üß† Generating AI summary...")
            self.speak_with_piper("I'll give you a summary.")

            summary_prompt = f"""Provide a brief executive summary of these emails in 2-3 sentences.
Focus on important senders and key topics.

{email_text_for_summary}

Summary (concise, action-item focused):"""

            response = requests.post(
                BRAIN_URL,
                json={"model": LLM_MODEL, "prompt": summary_prompt, "stream": False},
                timeout=60
            )
            summary = response.json().get('response', 'Could not generate summary.')

            self.log(f"\nüìß SUMMARY: {summary}")
            self.speak_with_piper(summary)

            # Log action
            self.log_vault_action(
                action_type="email_summarized",
                description="Summarized recent emails",
                metadata={"email_count": len(gmail_emails), "summary_length": len(summary)}
            )

        except Exception as e:
            logger.error(f"Error summarizing emails: {e}", exc_info=True)
            self.log(f"‚ùå Error summarizing emails: {e}")
            self.speak_with_piper("I encountered an error summarizing your emails.")
    
    def ask_for_clarification(self, original_query, ambiguous_intents):
        """Speak a clarifying question when an intent is ambiguous."""
        
        options = [INTENTS[i]['name'] for i in ambiguous_intents if i in INTENTS]
        
        if len(options) == 2:
            question = f"Sir, I'm not sure if you wanted to {options[0]} or {options[1]}. Could you clarify?"
        else:
            # Generic fallback if we have more than 2, or names are missing
            question = "I'm a little unclear on that. Could you please rephrase your request?"

        self.log(f"Jarvis: {question}")
        self.speak_with_piper(question)
        
        # We don't manage state here. The user's next command will be processed
        # from scratch, hopefully with more clarity. This is a robust, simple approach.

    def route_intent(self, raw_text):
        """Score and determine the user's intent from their command."""
        text_lower = raw_text.lower()
        scores = {}

        for intent, config in INTENTS.items():
            score = 0

            # Regex scoring (high priority)
            if 'regex' in config and re.search(config['regex'], text_lower):
                score += 10

            # Keyword scoring
            if 'keywords' in config:
                score += sum(1 for kw in config['keywords'] if kw in text_lower)

            # Required word scoring (bonus if present, disqualifies if not)
            if 'required' in config:
                if any(req in text_lower for req in config['required']):
                    score += 5  # Strong bonus for matching a required word
                elif score > 0: # If other keywords matched but not the required one
                    score = 0 # This intent is invalid

            # Blocker words (immediately disqualifies)
            if 'blockers' in config and any(blk in text_lower for blk in config['blockers']):
                score = 0

            if score > 0:
                scores[intent] = score

        if not scores:
            return "LLM_BRAIN", 0, {}

        # Sort by score to find the best match
        sorted_intents = sorted(scores.items(), key=lambda item: item[1], reverse=True)
        best_intent, best_score = sorted_intents[0]

        # --- Ambiguity Check ---
        # If the best score is not clearly better than the second best, it's ambiguous.
        if len(sorted_intents) > 1:
            second_best_intent, second_best_score = sorted_intents[1]
            # If scores are identical or very close (e.g., 2 vs 3), ask for clarification.
            if best_score > 0 and (best_score / second_best_score) < 1.5:
                logger.warning(f"Ambiguous intent: {best_intent} ({best_score}) vs {second_best_intent} ({second_best_score})")
                return "AMBIGUOUS", 0, {"ambiguous_intents": [best_intent, second_best_intent]}

        # --- Confidence Check ---
        # A score of 1 is a weak match (single, non-required keyword).
        # We require a stronger signal to trigger a tool.
        CONFIDENCE_THRESHOLD = 1
        if best_score <= CONFIDENCE_THRESHOLD:
            logger.debug(f"Low confidence for intent '{best_intent}' (score: {best_score}). Falling back to LLM.")
            return "LLM_BRAIN", best_score, {}

        logger.info(f"Intent routed: {best_intent} (score: {best_score})")
        return best_intent, best_score, {}

    def handle_self_knowledge(self, raw_text):
        """Handler for SELF_KNOWLEDGE intent."""
        logger.debug("Intent: Self-Knowledge")
        memory_facts = "\n".join(self.memory.get("facts", []))
        context = f"JARVIS MEMORY:\n{memory_facts}"
        self.fallback_to_llm(raw_text, context=context)

    def handle_dogzilla(self, raw_text):
        """Handler for PROJECT_DOGZILLA intent."""
        logger.debug("Intent: Dogzilla Project")
        dogzilla = self.memory.get("projects", {}).get("dogzilla", {})
        context = (f"DOGZILLA PROJECT:\n"
                   f"Name: {dogzilla.get('name', 'Dogzilla')}\n"
                   f"Type: {dogzilla.get('type', 'ESP32-based robotics')}\n"
                   f"Description: {dogzilla.get('description', '')}\n"
                   f"Status: {dogzilla.get('status', 'Active')}\n"
                   f"Components: {', '.join(dogzilla.get('components', []))}")
        self.fallback_to_llm(raw_text, context=context)

    def handle_weather(self, raw_text):
        """Handler for WEATHER intent."""
        self.status_var.set("Status: Searching Google...")
        logger.debug("Intent: Weather")
        context = self.google_search(f"weather in {LOCATION_OVERRIDE} today")
        if hasattr(self, 'dashboard') and context:
            self.dashboard.push_focus("docs", "Weather", f"Weather in {LOCATION_OVERRIDE}:\n\n{context[:400]}")
        self.last_intent = "search"
        self.fallback_to_llm(raw_text, context=context)

    def handle_email_reply_request(self, user_request):
        """
        Reply to the most recent email or a specific sender's email.
        
        Examples:
        - "Reply to the last email saying thanks"
        - "Reply to John saying I'll send it tomorrow"
        - "Send a reply: I agree with your proposal"
        """
        try:
            text_lower = user_request.lower()
            
            # Extract the reply message after common patterns
            import re
            
            reply_match = re.search(r'(?:saying|with|message:?)\s+(.+?)$', user_request, re.IGNORECASE)
            
            if not reply_match:
                self.log("‚ùå Could not identify reply message")
                self.speak_with_piper("What would you like me to say in the reply?")
                return
            
            reply_text = reply_match.group(1).strip()
            
            # Get recent emails to find which one to reply to
            logger.info("Fetching recent emails to find reply target...")
            self.status_var.set("Status: Fetching emails...")
            
            recent_emails = self.get_recent_emails(limit=1)
            
            if not recent_emails:
                self.log("‚ùå No recent emails found to reply to")
                self.speak_with_piper("You don't have any recent emails to reply to.")
                return
            
            # Get the most recent email
            email_to_reply = recent_emails[0]
            email_id = email_to_reply['id']
            sender = email_to_reply['sender']
            
            sender_name = self.extract_sender_name(sender)
            self.log(f"‚úâÔ∏è Reply pending confirmation ‚Äî to {sender_name}")
            self.log(f"   Message: {reply_text[:100]}")

            # Store as pending ‚Äî do NOT send yet
            self.pending_reply = {
                'email_id': email_id,
                'sender': sender,
                'sender_name': sender_name,
                'reply_text': reply_text
            }
            self.last_intent = "email"

            # Ask for confirmation
            confirmation_prompt = f"Shall I send that to {sender_name}?"
            self.speak_with_piper(confirmation_prompt)

            # Show on dashboard focus window
            self.dashboard.push_focus(
                content_type="email",
                title="Pending Reply ‚Äî Awaiting Confirmation",
                content=(f"To: {sender}\n\n"
                         f"Message:\n{reply_text}\n\n"
                         f"[Say YES to send or NO to cancel]")
            )
            
        except Exception as e:
            logger.error(f"Error replying to email: {e}", exc_info=True)
            self.log(f"‚ùå Reply failed: {e}")
            self.speak_with_piper("I encountered an error sending your reply.")
    
    def call_smart_model(self, prompt: str, timeout: int = 120) -> str:
        """Route to GPT-4o when the OpenAI key is available, fall back to Ollama.

        Used for tasks that require deep reasoning (code analysis, etc.) where
        the local llama3.1:8b model hallucinates or gives generic advice.
        """
        openai_key = os.getenv("OPENAI_API_KEY", "")
        if openai_key:
            try:
                from openai import OpenAI
                client = OpenAI(api_key=openai_key)
                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=2000,
                    timeout=timeout
                )
                logger.info("Smart model: used GPT-4o")
                return response.choices[0].message.content or ""
            except Exception as e:
                logger.warning(f"GPT-4o unavailable, falling back to Ollama: {e}")
        # Fallback ‚Äî local Ollama
        resp = requests.post(
            BRAIN_URL,
            json={"model": LLM_MODEL, "prompt": prompt, "stream": False, "options": {"temperature": 0.5}},
            timeout=timeout
        )
        logger.info("Smart model: used Ollama (fallback)")
        return resp.json().get('response', 'Analysis could not be completed.')

    def handle_optimization_request(self, user_request):
        """
        Multi-step intent handler for code analysis and documentation workflow.
        
        Flow:
        1. Confirm the task with the user via VAD
        2. Read the specified file content from vault
        3. Send to Ollama with optimization-focused prompt
        4. Create a Google Doc with the analysis
        5. Confirm completion with the URL
        
        Args:
            user_request: The user's original request
        """
        try:
            self.status_var.set("Status: üîß Analyzing code...")
            
            # Step 1: Extract which file the user wants to analyze
            text_lower = user_request.lower()
            
            # Try to determine which file to analyze
            target_file = None
            
            # Look for specific file references
            if "main" in text_lower:
                target_file = self.vault.get_file('main')
            elif "startup" in text_lower:
                target_file = self.vault.get_file('startup')
            elif "config" in text_lower:
                target_file = self.vault.get_file('config')
            elif "ear" in text_lower:
                target_file = self.vault.get_file('ear')
            else:
                # Try to extract filename from request
                # Look for patterns like "check [filename]"
                import re
                file_match = re.search(r'(?:check|analyze|optimize|read)\s+(?:the\s+)?(?:file\s+)?([a-zA-Z_]\w*\.py)', text_lower)
                if file_match:
                    filename = file_match.group(1)
                    target_file = self.vault.search_file(filename)
            
            if not target_file:
                self.log("‚ùå Could not identify which file to analyze. Please specify a file name.")
                self.speak_with_piper("I couldn't identify which file you'd like me to analyze. Please be more specific.")
                return
            
            # Log action
            self.log_vault_action(
                action_type="optimization_start",
                description=f"Starting optimization analysis for {os.path.basename(target_file)}"
            )
            
            # Step 2: Read the file content
            self.log(f"üìñ Reading: {os.path.basename(target_file)}")
            self.speak_with_piper("Reading the file now.")
            
            file_data = self.get_file_content(os.path.basename(target_file))
            
            if not file_data or not file_data.get('content'):
                self.log(f"‚ùå Could not read file: {target_file}")
                self.speak_with_piper("I had trouble reading the file. Please check it exists.")
                # Log failed read attempt
                self.log_vault_action(
                    action_type="optimization_failed",
                    description=f"Failed to read file for optimization: {os.path.basename(target_file)}"
                )
                return
            
            file_content = file_data['content']
            filename = file_data['filename']
            
            # Check gaming mode - skip AI processing
            if self.gaming_mode:
                self.log("‚ö†Ô∏è  Gaming Mode active - AI brain disabled")
                self.speak_with_piper("Gaming mode is enabled, code optimization is disabled.")
                return
            
            # Step 3: Send to Ollama/Brain for optimization analysis
            self.log("üß† Sending to AI brain for analysis...")
            self.speak_with_piper("Analyzing the code for optimization opportunities.")
            
            optimization_prompt = f"""You are an expert code reviewer analysing a specific codebase.

ARCHITECTURE (read carefully before analysing):
- This is a headless Python voice assistant ‚Äî no GUI, no web framework serving users.
- NO SQL database, no SQLAlchemy, no db_session, no User/Conversation ORM models.
- Conversation state is held in self.context_buffer (a Python list already in RAM).
- Persistent memory is jarvis_memory.json ‚Äî loaded once at startup, saved periodically.
- Flask runs in a single daemon background thread solely to receive n8n webhooks on port 5001.
- Background tasks use threading.Thread(daemon=True) ‚Äî no thread pool is needed or appropriate.
- There is nothing to cache ‚Äî all runtime state is already in memory.
DO NOT suggest: databases, SQLAlchemy, ThreadPoolExecutor for Flask.run(), or caching layers.

FILE TO ANALYSE: {filename}

CODE:
{file_content}

Identify the THREE most important real improvements specific to THIS codebase. For each:
1. Issue: Describe the actual problem found in this file
2. Impact: What concrete benefit would this provide?
3. Suggestion: Show a specific code change (not a generic pattern)

Plain text only ‚Äî no markdown, no bullet symbols, no code fences."""

            # Route to GPT-4o (smart model) ‚Äî falls back to Ollama if unavailable
            self.status_var.set("Status: üß† AI Analysis in Progress...")
            optimization_analysis = self.call_smart_model(optimization_prompt, timeout=120)
            self.log("‚úì Analysis complete")
            
            # Step 4: Create Google Doc with the analysis (Scribe Workflow)
            self.log("üìù Creating Google Doc...")
            self.speak_with_piper("Creating your optimization report document.")
            
            # Use write_optimization_to_doc() for clean Scribe workflow
            doc_result = self.write_optimization_to_doc(
                filename=filename,
                report_content=optimization_analysis
            )
            
            if not doc_result or not doc_result.get('success'):
                self.log("‚ùå Failed to create Google Doc")
                self.speak_with_piper("I encountered an error creating the document.")
                return
            
            doc_url = doc_result.get('doc_url')
            
            # Step 5: Log completion and confirm with user
            self.log_vault_action(
                action_type="optimization_complete",
                description=f"Completed optimization analysis for {filename}",
                metadata={
                    "filename": filename,
                    "doc_url": doc_url,
                    "analysis_length": len(optimization_analysis),
                    "folder_id": GOOGLE_DRIVE_FOLDER_ID
                }
            )
            
            # Confirmation message - Clear Scribe workflow confirmation
            doc_title = doc_result.get('title', 'Optimization Report')
            self.log(f"‚úÖ SCRIBE COMPLETE - Optimization Report Created")
            self.log(f"üìÑ Document: {doc_title}")
            self.log(f"üìÅ Saved to: Google Drive (Folder ID: {doc_result.get('folder_id') or GOOGLE_DRIVE_FOLDER_ID})")
            self.log(f"üîó URL: {doc_url}")
            
            # Speak confirmation with filename reference
            confirmation = f"Sir, the optimization report for {filename} is ready in your Drive."
            self.speak_with_piper(confirmation)
            self.log(f"üîä Confirmed: {confirmation}")

            # Display content in focus panel immediately
            if hasattr(self, 'dashboard'):
                preview = optimization_analysis[:3000]
                if len(optimization_analysis) > 3000:
                    preview += "\n\n[... truncated ‚Äî see Google Doc for full report]"
                self.dashboard.push_focus("docs", doc_title, preview)

            # Add to context buffer for conversation continuity
            self.add_to_context("Task", f"Optimization analysis completed: {filename}")
            self.add_to_context("Jarvis", f"Report created: {doc_title}")
            
            # Save memory with final state
            self.save_memory()
            
            if hasattr(self, 'dashboard'):
                self.dashboard.push_state(mode="idle")

            logger.info(f"‚úì Optimization workflow complete for {filename}")
            self.status_var.set("Status: Ready")
            
        except Exception as e:
            error_msg = f"Error in optimization workflow: {e}"
            logger.error(error_msg, exc_info=True)
            self.log(f"‚ùå {error_msg}")
            self.speak_with_piper("An error occurred during the analysis. Please check the console for details.")
    
    def handle_comparison_request(self, user_request):
        """
        Handle requests to compare two files.
        """
        try:
            self.status_var.set("Status: üîç Comparing files...")
            text_lower = user_request.lower()
            
            # Identify two file references from the request
            common_refs = ['main', 'startup', 'config', 'ear', 'memory', 'spec']
            explicit_files = re.findall(r'\b[\w-]+\.(?:py|json|txt|md|js|ts)\b', text_lower)
            
            potential_refs = []
            for ref in explicit_files:
                if ref not in potential_refs:
                    potential_refs.append(ref)
            for ref in common_refs:
                if ref in text_lower and ref not in potential_refs:
                    potential_refs.append(ref)

            if len(potential_refs) < 2:
                self.log("‚ùå Could not identify two files to compare.")
                self.speak_with_piper("I couldn't identify two distinct files to compare. Please specify them clearly.")
                return

            ref_a, ref_b = potential_refs[0], potential_refs[1]

            # Use get_file() via get_file_content() to resolve and read
            content_a = self.get_file_content(ref_a)
            content_b = self.get_file_content(ref_b)

            # Check for missing files and provide specific feedback
            if content_a and not content_b:
                msg = f"Sir, I found {content_a['filename']} but '{ref_b}' is missing from the index."
                self.log(f"‚ùå {msg}")
                self.speak_with_piper(msg)
                return
            elif not content_a and content_b:
                msg = f"Sir, I found {content_b['filename']} but '{ref_a}' is missing from the index."
                self.log(f"‚ùå {msg}")
                self.speak_with_piper(msg)
                return
            elif not content_a and not content_b:
                self.log(f"‚ùå Could not find files for '{ref_a}' or '{ref_b}'.")
                self.speak_with_piper(f"I'm sorry, I couldn't find either of those files in the vault index.")
                return
            
            file_a = {'name': content_a['filename']}
            file_b = {'name': content_b['filename']}
            
            self.log(f"üìã Comparing: {file_a['name']} vs {file_b['name']}")
            self.speak_with_piper(f"Comparing {file_a['name']} and {file_b['name']}.")

            # Check gaming mode
            if self.gaming_mode:
                self.log("‚ö†Ô∏è Gaming Mode active - AI brain disabled")
                self.speak_with_piper("Gaming mode is enabled, comparison is disabled.")
                return

            # Send to LLM
            self.log("üß† Analyzing comparison...")
            self.status_var.set("Status: üß† AI Analysis...")
            
            prompt = f"Comparison and Gap Analysis: Compare these two files and list exactly which features in File A are missing from File B.\n\nFILE A ({file_a['name']}):\n{content_a['content']}\n\nFILE B ({file_b['name']}):\n{content_b['content']}"

            analysis = self.call_smart_model(prompt, timeout=180)
            
            # Create Doc (optional but good for persistence)
            doc_title = f"Comparison: {file_a['name']} vs {file_b['name']} ({datetime.now().strftime('%Y-%m-%d %H:%M')})"
            self.create_optimization_doc(doc_title, analysis)
            
            self.log("‚úÖ Comparison complete")
            self.speak_with_piper(f"I've completed the comparison between {file_a['name']} and {file_b['name']}.")
            
            # Dashboard Focus
            if hasattr(self, 'dashboard'):
                self.dashboard.push_focus(
                    content_type="docs",
                    title=doc_title,
                    content=analysis[:3000]
                )
                self.dashboard.push_state(mode="idle")

        except Exception as e:
            logger.error(f"Comparison error: {e}", exc_info=True)
            self.log(f"‚ùå Comparison failed: {e}")
            self.speak_with_piper("I encountered an error during the comparison.")

    def add_to_context(self, role, message):
        """Add message to short-term context buffer."""
        self.context_buffer.append({"role": role, "message": message})
        logger.debug(f"Context buffer size: {len(self.context_buffer)}")
    
    def get_context_history(self):
        """Get formatted context history for LLM."""
        if not self.context_buffer:
            return ""
        history = "RECENT CONVERSATION (last exchanges):\n"
        for exchange in self.context_buffer:
            msg = exchange['message']
            truncated = (msg[:250] + "...") if len(msg) > 250 else msg
            history += f"  {exchange['role']}: {truncated}\n"
        return history
    
    def health_intervener(self):
        """Proactively propose breaks if Spencer is working too long."""
        health_profile = self.memory.get("master_profile", {}).get("health_profile", {})
        break_interval = health_profile.get("recommended_break_interval", 90)  # minutes
        
        elapsed_time = (time.time() - self.last_break_time) / 60  # Convert to minutes
        
        if elapsed_time > break_interval:
            logger.info(f"Health check: {elapsed_time:.0f} minutes since last break")
            self.last_break_time = time.time()
            msg = ("Sir, you have been working for over "
                   f"{int(elapsed_time)} minutes. "
                   "I recommend a short break when you are ready.")
            self.log(f"üíä {msg}")
            self.speak_with_piper(msg)
            return True
        return False
    
    # ===== PROJECT VAULT SYSTEM =====
    def scan_vault_projects(self):
        """Scan vault root and discover all available projects."""
        try:
            self.available_projects = []
            if os.path.isdir(self.vault_root):
                for item in os.listdir(self.vault_root):
                    item_path = os.path.join(self.vault_root, item)
                    if os.path.isdir(item_path):
                        self.available_projects.append(item)
                logger.info(f"‚úì Vault scan complete: {len(self.available_projects)} projects found")
                logger.debug(f"Projects: {', '.join(self.available_projects)}")
            else:
                logger.error(f"Vault root not found: {self.vault_root}")
        except Exception as e:
            logger.error(f"Vault scan failed: {e}")
    
    def list_vault_projects(self):
        """Return formatted list of all projects in vault (read-only)."""
        try:
            self.scan_vault_projects()  # Refresh list
            if not self.available_projects:
                return "No projects found in vault."
            
            project_list = "Projects in your Vault:\n"
            for project in sorted(self.available_projects):
                marker = "[ACTIVE]" if project == self.active_project else ""
                project_list += f"  ‚Ä¢ {project} {marker}\n"
            
            logger.info(f"Vault projects listed (active: {self.active_project})")
            return project_list
        except Exception as e:
            logger.error(f"Failed to list vault projects: {e}")
            return f"Error reading vault: {e}"
    
    def read_project_file(self, relative_path):
        """Read a file from the active project (read-only).
        
        Args:
            relative_path: Path relative to active project folder
            
        Returns:
            File contents as string
        """
        try:
            if not self.active_project in self.available_projects:
                return f"Project '{self.active_project}' not found in vault."
            
            full_path = os.path.join(self.vault_root, self.active_project, relative_path)
            
            # Security: Prevent directory traversal
            real_path = os.path.realpath(full_path)
            vault_base = os.path.realpath(self.vault_root)
            if not real_path.startswith(vault_base):
                logger.warning(f"Security: Attempted directory traversal: {full_path}")
                return "Error: Invalid file path (directory traversal attempted)."
            
            if not os.path.exists(real_path):
                return f"File not found: {relative_path}"
            
            if not os.path.isfile(real_path):
                return f"Path is not a file: {relative_path}"
            
            # Read file (limiting size to prevent massive outputs)
            max_size = 100000  # 100KB limit
            file_size = os.path.getsize(real_path)
            
            if file_size > max_size:
                return f"File too large ({file_size} bytes). Showing first 25KB:\n\n" + open(real_path, 'r', encoding='utf-8', errors='ignore').read()[:25000]
            
            with open(real_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            logger.info(f"Vault read: {self.active_project}/{relative_path}")
            return content
            
        except Exception as e:
            logger.error(f"Failed to read vault file: {e}")
            return f"Error reading file: {e}"
    
    def search_vault(self, query):
        """Search for keyword recursively across all vault projects (read-only).
        
        Args:
            query: Search term (case-insensitive)
            
        Returns:
            Formatted search results
        """
        try:
            query_lower = query.lower()
            results = {}
            files_searched = 0
            
            for project in self.available_projects:
                project_path = os.path.join(self.vault_root, project)
                
                for root, dirs, files in os.walk(project_path):
                    # Skip common non-text directories
                    dirs[:] = [d for d in dirs if d not in ['.git', '__pycache__', 'node_modules', '.venv', 'venv']]
                    
                    for file in files:
                        # Skip binary files
                        if any(file.endswith(ext) for ext in ['.pyc', '.exe', '.dll', '.so', '.bin']):
                            continue
                        
                        files_searched += 1
                        file_path = os.path.join(root, file)
                        
                        try:
                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                content = f.read()
                                if query_lower in content.lower():
                                    # Store match with line number
                                    rel_file = os.path.relpath(file_path, project_path)
                                    if project not in results:
                                        results[project] = []
                                    results[project].append(rel_file)
                        except Exception as e:
                            logger.debug("File search skip (%s): %s", file_path, e)

            # Format results
            if not results:
                return f"No matches found for '{query}' in {files_searched} files searched."
            
            output = f"Search Results for '{query}' ({files_searched} files searched):\n\n"
            for project in sorted(results.keys()):
                output += f"üìÅ {project}:\n"
                for file in sorted(results[project])[:10]:  # Limit to 10 per project
                    output += f"   ‚Ä¢ {file}\n"
                if len(results[project]) > 10:
                    output += f"   ... and {len(results[project]) - 10} more\n"
            
            logger.info(f"Vault search: '{query}' found in {sum(len(v) for v in results.values())} files")
            return output
            
        except Exception as e:
            logger.error(f"Vault search failed: {e}")
            return f"Search error: {e}"
    
    def detect_and_switch_project(self, text):
        """Auto-detect if user mentions a project and switch context (case-insensitive).
        
        Returns:
            True if project was switched, False otherwise
        """
        try:
            text_lower = text.lower()
            
            for project in self.available_projects:
                if project.lower() in text_lower:
                    if project != self.active_project:
                        old_project = self.active_project
                        self.active_project = project
                        logger.info(f"üîÄ Project switch: {old_project} ‚Üí {self.active_project}")
                        self.log(f"üìÅ Switched to project: {self.active_project}")
                        return True
        except Exception as e:
            logger.error(f"Project detection failed: {e}")
        
        return False
    
    def start_vad_monitor(self):
        """Start VAD monitor thread for barge-in detection (Normal Mode only)."""
        # Only enable barge-in in Normal Mode (not Conversation Mode)
        if not self.barge_in_enabled or self.vad_monitor_active or self.conversation_mode:
            return
        
        logger.info("Starting VAD monitor for barge-in detection...")
        self.vad_monitor_active = True
        self.vad_monitor_thread = threading.Thread(target=self.vad_monitor_loop, daemon=True)
        self.vad_monitor_thread.start()
        logger.debug("VAD monitor thread started")
    
    def stop_vad_monitor(self):
        """Stop VAD monitor thread."""
        if not self.vad_monitor_active:
            return
        
        logger.info("Stopping VAD monitor...")
        self.vad_monitor_active = False
        if self.vad_monitor_thread:
            self.vad_monitor_thread.join(timeout=1.0)
            self.vad_monitor_thread = None
        logger.debug("VAD monitor stopped")
    
    def vad_monitor_loop(self):
        """Monitor microphone for speech while Jarvis is speaking (barge-in detection)."""
        logger.info("VAD monitor loop active")
        
        # Wait for barge_in_delay before starting to actually monitor
        # This prevents Jarvis from interrupting himself when speech starts
        if self.barge_in_delay > 0:
            logger.debug(f"VAD monitor waiting {self.barge_in_delay}s before starting...")
            start_time = time.time()
            while time.time() - start_time < self.barge_in_delay:
                if not self.vad_monitor_active or not self.is_speaking:
                    logger.debug("VAD monitor cancelled during startup delay")
                    return
                time.sleep(0.1)
            logger.debug("VAD monitor delay complete - starting barge-in detection")
        
        try:
            while self.vad_monitor_active:
                # Stop if conversation mode is enabled (no barge-in needed there)
                if self.conversation_mode:
                    logger.info("Conversation mode enabled - stopping VAD monitor")
                    break
                
                # Only monitor when Jarvis is speaking
                if not self.is_speaking:
                    time.sleep(0.05)
                    continue
                
                # Check if we have recorder available
                if self.recorder is None or self.porcupine is None:
                    time.sleep(0.05)
                    continue
                
                try:
                    # Read audio frame (non-blocking)
                    pcm = self.recorder.read()
                    
                    # Calculate energy
                    energy = self.detect_speech_energy(pcm)
                    
                    # If energy exceeds barge-in threshold while speaking
                    if energy > self.barge_in_threshold:
                        logger.warning(f"BARGE-IN detected! Energy: {energy:.0f} (threshold: {self.barge_in_threshold})")
                        self.interrupt_requested = True
                        # Brief pause to let interruption take effect
                        time.sleep(0.1)
                        
                except Exception as e:
                    logger.error(f"VAD monitor frame error: {e}")
                    time.sleep(0.05)
                    
        except Exception as e:
            logger.error(f"VAD monitor loop error: {e}", exc_info=True)
        finally:
            logger.info("VAD monitor loop terminated")
    
    def handle_n8n_webhook(self, notification):
        """Process notifications from n8n workflow."""
        priority = notification.get("priority", "ROUTINE")
        message = notification.get("message", "No content")
        source = notification.get("source", "Unknown")
        metadata = notification.get("metadata", {})  # Extract metadata for emails, etc.
        
        logger.info(f"n8n Notification [{priority}]: {source} - {message}")
        
        if priority == "URGENT":
            self.urgent_interrupt = True
            logger.warning(f"URGENT notification queued: {message}")
            if hasattr(self, 'dashboard'):
                self.dashboard.push_focus("email", f"URGENT ‚Äî {source}", message)
        elif str(priority).upper() == "HIGH":
            queued_msg = {
                "source": source,
                "message": message,
                "timestamp": datetime.now().isoformat(),
                "metadata": metadata,
            }
            with self.queue_lock:
                self.notification_queue.append(queued_msg)
            logger.debug(f"High-priority notification queued: {message}")
        else:
            # Queue with metadata preserved
            queued_msg = {
                "source": source, 
                "message": message, 
                "timestamp": datetime.now().isoformat(),
                "metadata": metadata,
            }
            with self.queue_lock:
                self.notification_queue.append(queued_msg)
            logger.debug(f"Routine notification queued: {message}")

    def process_notification_queue(self, context="idle"):
        """Process and announce queued notifications.

        Args:
            context (str): "idle" for periodic checks, "busy" for post-conversation summary.
        """
        with self.queue_lock:
            if not self.notification_queue:
                return
            queue_copy = list(self.notification_queue)
            self.notification_queue = []

        if self.is_speaking:
            # Re-queue if speaking, to be processed later
            with self.queue_lock:
                self.notification_queue.extend(queue_copy)
            return

        self.log("üì© Processing queued notifications...")
        by_source = collections.defaultdict(list)
        for n in queue_copy:
            by_source[n.get('source', 'Unknown')].append(n)

        parts = []
        focus_lines = []
        for src, items in sorted(by_source.items()):
            if len(items) == 1:
                parts.append(items[0]['message'])
            else:
                plural_src = src + 's' if not src.endswith('s') else src
                parts.append(f"you have {len(items)} {plural_src} updates")
            for item in items:
                meta = item.get('metadata', {})
                line = f"‚Ä¢ From: {self.extract_sender_name(meta.get('sender',''))}\n  Subject: {meta.get('subject','')}"
                focus_lines.append(line)

        if not parts: return

        summary = ("Also, " if context == "busy" else "Sir, ") + ", and ".join(parts) + "."
        self.speak_with_piper(summary)

    def interrupt_and_speak(self, message):
        """Interrupt current activity and speak urgent message."""
        logger.warning(f"INTERRUPT: {message}")
        self.log(f"üö® URGENT: {message}")
        # The message will be processed before process_conversation completes
        # due to self.urgent_interrupt flag
        self.speak_with_piper(message)

    def toggle_gaming_mode(self):
        """Gaming Mode disables the microphone completely and frees resources."""
        # Toggle the state
        self.gaming_mode = not self.gaming_mode
        
        if self.gaming_mode:
            self.log("üéÆ Gaming Mode: ENABLED")
            self.log("   ‚Üí Mic disabled, resources freed")
            logger.info("Gaming mode activated - stopping all listening and freeing resources")
            
            # Stop listening and clean up resources
            self.is_listening = False
            self.cleanup_audio_resources()
            
            # Update dashboard: idle when gaming mode enabled
            if hasattr(self, 'dashboard'):
                self.dashboard.push_state(mode="idle", gamingMode=True)
            
            # Disable conversation mode
            self.conversation_mode = False
            
            self.status_var.set("Status: Gaming Mode - Mic Off")
        else:
            self.log("üéÆ Gaming Mode: DISABLED")
            self.log("   ‚Üí Returning to Normal Mode")
            logger.info("Gaming mode deactivated - returning to normal mode")
            self.status_var.set("Status: Standby")
            
            # Update dashboard: idle when gaming mode disabled
            if hasattr(self, 'dashboard'):
                self.dashboard.push_state(mode="idle", gamingMode=False)
            
            # Restart listening in normal mode
            self.start_listening()

    def toggle_conversation_mode(self):
        """Conversation Mode disables wake word for continuous chat."""
        # Toggle the state
        self.conversation_mode = not self.conversation_mode
        
        if self.conversation_mode:
            # Can't enable if gaming mode is on
            if self.gaming_mode:
                self.log("‚ö†Ô∏è  Cannot enable Conversation Mode during Gaming Mode")
                logger.warning("Attempted to enable conversation mode during gaming mode")
                self.conversation_mode = False
                return
            
            self.log("üí¨ Conversation Mode: ENABLED")
            self.log("   ‚Üí Open mic - just speak naturally!")
            self.log("   ‚Üí No wake word needed, automatic speech detection")
            logger.info("Conversation mode activated - continuous speech detection with VAD")
            self.status_var.set("Status: üí¨ Speak freely...")
            
            # Update dashboard: conversation mode enabled
            if hasattr(self, 'dashboard'):
                self.dashboard.push_state(mode="idle", conversationalMode=True)
            
            # Ensure listening is active
            if not self.is_listening:
                self.start_listening()
        else:
            self.log("üí¨ Conversation Mode: DISABLED")
            self.log("   ‚Üí Back to wake word detection")
            logger.info("Conversation mode deactivated - back to normal wake word mode")
            self.status_var.set("Status: Monitoring...")
            
            # Update dashboard: conversation mode disabled
            if hasattr(self, 'dashboard'):
                self.dashboard.push_state(mode="idle", conversationalMode=False)

    # --- TOOLS: SEARCH, CALENDAR, GMAIL ---
    def google_search(self, query):
        """Perform Google search using Custom Search API with API key."""
        try:
            if not GOOGLE_CSE_API_KEY or not GOOGLE_CSE_CX:
                logger.error("Google Search API key or CX is not configured.")
                return "Search is not configured. The API key is missing."

            service = build("customsearch", "v1", developerKey=GOOGLE_CSE_API_KEY)
            res = service.cse().list(q=query, cx=GOOGLE_CSE_CX, num=3).execute()
            items = res.get('items', [])

            if not items:
                logger.warning(f"Google Custom Search for '{query}' returned 0 items. The CSE might be misconfigured for general web searches.")
                return ""  # Empty string signifies no results found

            return "\n".join([f"{i['title']}: {i['snippet']}" for i in items])
        except HttpError as e:
            error_details = json.loads(e.content).get('error', {})
            message = error_details.get('message', str(e))
            logger.error(f"Google Search API HTTP error for query '{query}': {message}")
            return f"There was an error with the search API: {message}"
        except Exception as e:
            logger.error(f"Google Search failed for query '{query}': {e}", exc_info=True)
            return []

    def get_calendar(self):
        """Get upcoming calendar events using Google Calendar API (real data)."""
        try:
            creds = get_google_creds()
            service = build('calendar', 'v3', credentials=creds)

            import datetime as _dt
            now = _dt.datetime.now(_dt.timezone.utc).isoformat()
            events_result = service.events().list(
                calendarId='primary',
                timeMin=now,
                maxResults=10,
                singleEvents=True,
                orderBy='startTime'
            ).execute()
            events = events_result.get('items', [])

            if not events:
                self.last_calendar_events = []
                return "Your calendar is clear ‚Äî no upcoming events."

            self.last_calendar_events = []
            lines = []
            for i, event in enumerate(events, 1):
                start = event['start'].get('dateTime', event['start'].get('date', ''))
                try:
                    if 'T' in start:
                        dt = datetime.fromisoformat(start.replace('Z', '+00:00'))
                        # Use %I and lstrip('0') for cross-platform compatibility (Windows doesn't support %-I)
                        time_str = dt.strftime('%A %d %b at %I:%M %p').lstrip('0')
                    else:
                        dt = datetime.fromisoformat(start)
                        time_str = dt.strftime('%A %d %b (all day)')
                except Exception as e:
                    logger.warning(f"Calendar date parse failed for '{start}': {e}")
                    time_str = start

                summary = event.get('summary', 'Untitled event')
                lines.append(f"{i}. {summary} ‚Äî {time_str}")
                self.last_calendar_events.append({
                    'index': i,
                    'id': event.get('id'),
                    'summary': summary,
                    'start': start,
                    'start_dt': time_str
                })

            return "Upcoming events:\n" + "\n".join(lines)

        except Exception as e:
            self.log(f"Calendar API Error: {e}")
            logger.error(f"Calendar error: {e}", exc_info=True)
            return "Error accessing calendar."
    
    # ===== RELATIVE TIME PARSER =====
    def parse_relative_datetime(self, time_expr):
        """Parse relative time expressions into datetime objects.

        Handles: tomorrow [morning/afternoon/evening], this evening, tonight,
                 after lunch, in X minutes/hours, next week, day names,
                 later, this afternoon.

        Returns:
            (start_dt, end_dt) tuple, or (None, None) if no time found.
        """
        import re
        now = datetime.now()
        text = time_expr.lower().strip()

        # "in X minutes/hours/days"
        m = re.search(r'in\s+(\d+)\s+(minute|hour|day)s?', text)
        if m:
            amount = int(m.group(1))
            unit = m.group(2)
            delta = {'minute': timedelta(minutes=amount),
                     'hour': timedelta(hours=amount),
                     'day': timedelta(days=amount)}[unit]
            start_dt = now + delta
            return start_dt, start_dt + timedelta(hours=1)

        # Day-of-week names
        day_names = ['monday', 'tuesday', 'wednesday', 'thursday',
                     'friday', 'saturday', 'sunday']
        for i, day in enumerate(day_names):
            if day in text:
                days_ahead = (i - now.weekday()) % 7 or 7
                base = (now + timedelta(days=days_ahead)).replace(
                    second=0, microsecond=0)
                hour = 9
                if 'afternoon' in text:
                    hour = 14
                elif 'evening' in text:
                    hour = 19
                start_dt = base.replace(hour=hour, minute=0)
                return start_dt, start_dt + timedelta(hours=1)

        # tomorrow
        if 'tomorrow' in text:
            base = (now + timedelta(days=1)).replace(second=0, microsecond=0)
            hour = 9
            if 'afternoon' in text:
                hour = 14
            elif 'evening' in text or 'night' in text:
                hour = 19
            start_dt = base.replace(hour=hour, minute=0)
            return start_dt, start_dt + timedelta(hours=1)

        # this evening / tonight
        if 'this evening' in text or 'tonight' in text:
            start_dt = now.replace(hour=19, minute=0, second=0, microsecond=0)
            if start_dt <= now:
                start_dt += timedelta(days=1)
            return start_dt, start_dt + timedelta(hours=1)

        # after lunch
        if 'after lunch' in text:
            start_dt = now.replace(hour=13, minute=30, second=0, microsecond=0)
            if start_dt <= now:
                start_dt += timedelta(days=1)
            return start_dt, start_dt + timedelta(hours=1)

        # next week
        if 'next week' in text:
            start_dt = (now + timedelta(days=7)).replace(
                hour=9, minute=0, second=0, microsecond=0)
            return start_dt, start_dt + timedelta(hours=1)

        # later / this afternoon
        if 'later' in text or 'this afternoon' in text:
            if now.hour < 14:
                start_dt = now.replace(hour=14, minute=0, second=0, microsecond=0)
            else:
                start_dt = now + timedelta(hours=2)
                start_dt = start_dt.replace(second=0, microsecond=0)
            return start_dt, start_dt + timedelta(hours=1)

        return None, None

    # ===== CALENDAR WRITE METHODS =====
    def create_calendar_event(self, title, start_dt, end_dt, description=None):
        """Create a new Google Calendar event."""
        try:
            creds = get_google_creds()
            service = build('calendar', 'v3', credentials=creds)
            event_body = {
                'summary': title,
                'start': {'dateTime': start_dt.isoformat(), 'timeZone': 'Europe/London'},
                'end':   {'dateTime': end_dt.isoformat(),   'timeZone': 'Europe/London'},
            }
            if description:
                event_body['description'] = description
            event = service.events().insert(
                calendarId='primary', body=event_body).execute()
            logger.info(f"‚úì Calendar event created: {title}")
            return event
        except Exception as e:
            logger.error(f"Calendar create error: {e}")
            return None

    def update_calendar_event(self, event_id, new_start_dt=None,
                              new_end_dt=None, new_title=None):
        """Update an existing calendar event."""
        try:
            creds = get_google_creds()
            service = build('calendar', 'v3', credentials=creds)
            event = service.events().get(
                calendarId='primary', eventId=event_id).execute()
            if new_title:
                event['summary'] = new_title
            if new_start_dt:
                event['start'] = {'dateTime': new_start_dt.isoformat(),
                                  'timeZone': 'Europe/London'}
            if new_end_dt:
                event['end'] = {'dateTime': new_end_dt.isoformat(),
                                'timeZone': 'Europe/London'}
            updated = service.events().update(
                calendarId='primary', eventId=event_id, body=event).execute()
            logger.info(f"‚úì Calendar event updated: {event.get('summary')}")
            return updated
        except Exception as e:
            logger.error(f"Calendar update error: {e}")
            return None

    def delete_calendar_event(self, event_id):
        """Delete (cancel) a calendar event."""
        try:
            creds = get_google_creds()
            service = build('calendar', 'v3', credentials=creds)
            service.events().delete(
                calendarId='primary', eventId=event_id).execute()
            logger.info(f"‚úì Calendar event deleted: {event_id}")
            return True
        except Exception as e:
            logger.error(f"Calendar delete error: {e}")
            return False

    def handle_calendar_action(self, user_request):
        """Handle calendar create / move / cancel requests.

        Examples:
          "Book a call with David tomorrow afternoon"
          "Move the first one to Thursday"
          "Cancel my 2pm meeting"
        """
        import re
        text = user_request.lower()

        cancel_words  = ['cancel', 'delete', 'remove']
        modify_words  = ['move', 'reschedule', 'change', 'update', 'shift']

        def _pick_event_by_index(text):
            """Return calendar event dict from last_calendar_events by ordinal."""
            idx_map = {'first': 1, '1st': 1, 'second': 2, '2nd': 2,
                       'third': 3, '3rd': 3}
            m = re.search(
                r'\b(first|1st|second|2nd|third|3rd|\d+)\b', text)
            if not m:
                return None
            raw = m.group(1)
            idx = idx_map.get(raw) or (int(raw) if raw.isdigit() else None)
            if idx and 1 <= idx <= len(self.last_calendar_events):
                return self.last_calendar_events[idx - 1]
            return None

        # --- CANCEL ---
        if any(w in text for w in cancel_words):
            if not self.last_calendar_events:
                self.speak_with_piper(
                    "Check your calendar first so I know which event to cancel.")
                return
            event = _pick_event_by_index(text)
            if not event:
                self.speak_with_piper(
                    "Which event? Say 'cancel the first one' or similar.")
                return
            if self.delete_calendar_event(event['id']):
                msg = f"Done. I've cancelled {event['summary']}."
                self.speak_with_piper(msg)
                self.add_to_context("User", user_request)
                self.add_to_context("Jarvis", msg)
                self.last_intent = "calendar"
                self.log_vault_action(
                    "calendar_deleted",
                    f"Cancelled: {event['summary']}")
                updated = self.get_calendar()
                self.dashboard.push_focus("docs", "Calendar", updated)
            else:
                self.speak_with_piper("I had trouble cancelling that event.")
            return

        # --- MOVE / RESCHEDULE ---
        if any(w in text for w in modify_words):
            if not self.last_calendar_events:
                self.speak_with_piper(
                    "Check your calendar first so I know which event to move.")
                return
            event = _pick_event_by_index(text)
            if not event:
                self.speak_with_piper(
                    "Which event? Say 'move the first one' or similar.")
                return
            start_dt, end_dt = self.parse_relative_datetime(user_request)
            if not start_dt:
                self.speak_with_piper(
                    "When would you like to move it to?")
                self.last_intent = "calendar"
                return
            updated = self.update_calendar_event(
                event['id'], new_start_dt=start_dt, new_end_dt=end_dt)
            if updated:
                new_time = start_dt.strftime('%A %d %b at %I:%M %p').lstrip('0')
                msg = f"Done. I've moved {event['summary']} to {new_time}."
                self.speak_with_piper(msg)
                self.add_to_context("User", user_request)
                self.add_to_context("Jarvis", msg)
                self.last_intent = "calendar"
                self.log_vault_action(
                    "calendar_updated",
                    f"Moved {event['summary']} to {new_time}")
                cal_text = self.get_calendar()
                self.dashboard.push_focus("docs", "Calendar", cal_text)
            else:
                self.speak_with_piper("I had trouble updating that event.")
            return

        # --- CREATE ---
        start_dt, end_dt = self.parse_relative_datetime(user_request)
        # Strip scheduling verbs to isolate the event title
        raw_title = user_request
        for phrase in ['book', 'schedule', 'add', 'create', 'set up',
                       'arrange', 'remind me about', 'remind me to']:
            raw_title = re.sub(
                r'\b' + re.escape(phrase) + r'\b', '', raw_title,
                flags=re.IGNORECASE)
        # Strip time words from title
        time_words = [
            'tomorrow', 'morning', 'afternoon', 'evening', 'tonight',
            'monday', 'tuesday', 'wednesday', 'thursday', 'friday',
            'saturday', 'sunday', 'next week', 'after lunch', 'later',
            r'in \d+ \w+']
        for w in time_words:
            raw_title = re.sub(
                r'\b' + w + r'\b', '', raw_title, flags=re.IGNORECASE)
        title = re.sub(r'\s+', ' ', raw_title).strip(' ,-') or "New Event"

        if not start_dt:
            # No time found ‚Äî ask and remember the title for follow-up
            self.speak_with_piper("When would you like to schedule that?")
            self.pending_calendar_title = title
            self.last_intent = "calendar"
            return

        event = self.create_calendar_event(title, start_dt, end_dt)
        if event:
            new_time = start_dt.strftime('%A %d %b at %I:%M %p').lstrip('0')
            msg = f"Done. I've booked {title} for {new_time}."
            self.speak_with_piper(msg)
            self.add_to_context("User", user_request)
            self.add_to_context("Jarvis", msg)
            self.last_intent = "calendar"
            self.log_vault_action(
                "calendar_created", f"Created: {title} at {new_time}")
            cal_text = self.get_calendar()
            self.dashboard.push_focus("docs", "Calendar", cal_text)
        else:
            self.speak_with_piper("I had trouble creating that event.")

    def _handle_show_email_from_list(self, user_request):
        """Contextual handler to display a single email from a list in the session."""
        # This is a placeholder for a more complete implementation.
        self.speak_with_piper("This function to show a specific email is not yet fully implemented.")

    # ===== EMAIL ARCHIVE / TRASH =====
    def archive_email(self, message_id):
        """Archive an email (remove from INBOX label)."""
        try:
            creds = get_google_creds()
            service = build('gmail', 'v1', credentials=creds)
            service.users().messages().modify(
                userId='me',
                id=message_id,
                body={'removeLabelIds': ['INBOX']}
            ).execute()
            logger.info(f"‚úì Email archived: {message_id}")
            return True
        except Exception as e:
            logger.error(f"Email archive error: {e}")
            return False

    def trash_email(self, message_id):
        """Move an email to trash."""
        try:
            creds = get_google_creds()
            service = build('gmail', 'v1', credentials=creds)
            service.users().messages().trash(
                userId='me', id=message_id).execute()
            logger.info(f"‚úì Email trashed: {message_id}")
            return True
        except Exception as e:
            logger.error(f"Email trash error: {e}")
            return False

    def handle_email_management_request(self, user_request):
        """Handle archive / delete / mark-handled requests.

        Examples:
          "Mark that handled"
          "Archive that email"
          "Delete the last email"
        """
        text = user_request.lower()

        # Use last email in context, else fetch the most recent
        target = self.last_email_context
        if not target:
            recent = self.get_recent_emails(limit=1)
            if recent:
                target = recent[0]

        if not target:
            self.speak_with_piper(
                "I don't have an email in context. "
                "Try summarizing or searching your emails first.")
            return

        email_id = target.get('id')
        sender_name = self.extract_sender_name(target.get('sender', 'that sender'))

        if any(w in text for w in ['trash', 'delete', 'bin']):
            if self.trash_email(email_id):
                msg = f"Done. Email from {sender_name} moved to trash."
                self.speak_with_piper(msg)
                self.add_to_context("User", user_request)
                self.add_to_context("Jarvis", msg)
                self.last_intent = "email"
                self.log_vault_action(
                    "email_trashed", f"Trashed email from {sender_name}")
            else:
                self.speak_with_piper("I had trouble deleting that email.")
        else:
            # archive / mark handled
            if self.archive_email(email_id):
                msg = f"Done. Email from {sender_name} archived."
                self.speak_with_piper(msg)
                self.add_to_context("User", user_request)
                self.add_to_context("Jarvis", msg)
                self.last_intent = "email"
                self.log_vault_action(
                    "email_archived", f"Archived email from {sender_name}")
            else:
                self.speak_with_piper("I had trouble archiving that email.")

    # ===== PENDING CONFIRMATION CHECK =====
    def check_pending_confirmation(self, text):
        """Check if user is responding to a pending action requiring confirmation.

        Returns True if the input was fully handled (caller should return).
        """
        text_lower = text.lower().strip()

        confirm_words = ['yes', 'yeah', 'yep', 'send it', 'send that',
                         'go ahead', 'do it', 'ok', 'okay', 'confirm',
                         'correct', 'sure', 'please']
        deny_words   = ['no', 'nope', 'cancel', "don't", 'dont',
                        'stop', 'abort', 'wait', 'hold on', 'actually']

        # --- Pending email reply ---
        if self.pending_reply:
            if any(w in text_lower for w in confirm_words):
                rd = self.pending_reply
                self.pending_reply = None
                success = self.reply_to_email(rd['email_id'], rd['reply_text'])
                if success:
                    msg = f"Reply sent to {rd['sender_name']}."
                    self.log(f"‚úì {msg}")
                    self.speak_with_piper(msg)
                    self.log_vault_action(
                        "email_replied",
                        f"Replied to {rd['sender']}",
                        metadata={
                            "recipient": rd['sender'],
                            "message_preview": rd['reply_text'][:100],
                            "timestamp": datetime.now().isoformat()
                        })
                    self.last_intent = "email"
                else:
                    self.speak_with_piper("I had trouble sending that reply.")
                return True

            if any(w in text_lower for w in deny_words):
                self.pending_reply = None
                self.speak_with_piper("Reply cancelled.")
                self.log("‚úâÔ∏è Reply cancelled by user.")
                return True

            # Ambiguous ‚Äî remind user there's a pending action
            self.speak_with_piper(
                f"Just to confirm ‚Äî shall I send that reply to "
                f"{self.pending_reply['sender_name']}?")
            return True

        # --- Pending calendar event (waiting for time) ---
        if self.pending_calendar_title:
            start_dt, end_dt = self.parse_relative_datetime(text)
            if start_dt:
                title = self.pending_calendar_title
                self.pending_calendar_title = None
                event = self.create_calendar_event(title, start_dt, end_dt)
                if event:
                    new_time = start_dt.strftime(
                        '%A %d %b at %I:%M %p').lstrip('0')
                    msg = f"Done. I've booked {title} for {new_time}."
                    self.speak_with_piper(msg)
                    self.add_to_context("User", text)
                    self.add_to_context("Jarvis", msg)
                    self.last_intent = "calendar"
                    self.log_vault_action(
                        "calendar_created", f"Created: {title} at {new_time}")
                    cal_text = self.get_calendar()
                    self.dashboard.push_focus("docs", "Calendar", cal_text)
                else:
                    self.speak_with_piper("I had trouble creating that event.")
                return True

            if any(w in text_lower for w in deny_words):
                self.pending_calendar_title = None
                self.speak_with_piper("Booking cancelled.")
                return True

        return False

    # ===== TASK / REMINDER SYSTEM =====
    def add_task(self, description, remind_at=None):
        """Add a task to the task list with an optional timed reminder."""
        task = {
            'id': int(time.time() * 1000),
            'description': description,
            'created': datetime.now().isoformat(),
            'remind_at': remind_at.isoformat() if remind_at else None,
            'done': False,
            'reminded': False
        }
        self.tasks.append(task)
        self.memory['tasks'] = self.tasks
        self.save_memory()
        self.log_vault_action(
            'task_created',
            f"Task added: {description}",
            metadata={'task_id': task['id'],
                      'remind_at': task['remind_at']})
        return task

    def list_tasks(self, show_done=False):
        """Return a formatted string of pending (or all) tasks."""
        items = self.tasks if show_done else [t for t in self.tasks if not t['done']]
        if not items:
            return "No pending tasks."
        lines = []
        for i, t in enumerate(items, 1):
            remind_str = ""
            if t.get('remind_at'):
                try:
                    rdt = datetime.fromisoformat(t['remind_at'])
                    remind_str = f"  [Due: {rdt.strftime('%a %d %b %I:%M %p')}]"
                except Exception:
                    pass
            done_str = " ‚úì" if t.get('done') else ""
            lines.append(f"{i}. {t['description']}{remind_str}{done_str}")
        return "\n".join(lines)

    def mark_task_done(self, query):
        """Mark a task done by 1-based index or partial description match.

        Returns the task description string if found, else None.
        """
        import re
        active = [t for t in self.tasks if not t['done']]
        # Numeric index
        m = re.search(r'\b(\d+)\b', query)
        if m:
            idx = int(m.group(1)) - 1
            if 0 <= idx < len(active):
                active[idx]['done'] = True
                self.memory['tasks'] = self.tasks
                self.save_memory()
                self.log_vault_action(
                    'task_completed',
                    f"Completed: {active[idx]['description']}")
                return active[idx]['description']
        # Keyword match
        q_lower = query.lower()
        for task in active:
            words = [w for w in q_lower.split() if len(w) > 3]
            if words and any(w in task['description'].lower() for w in words):
                task['done'] = True
                self.memory['tasks'] = self.tasks
                self.save_memory()
                self.log_vault_action(
                    'task_completed', f"Completed: {task['description']}")
                return task['description']
        return None

    def reminder_scheduler_loop(self):
        """Background thread: fire due reminders and process notification queue every 30 seconds."""
        IDLE_THRESHOLD = 60  # seconds
        while True:
            try:
                now = datetime.now()
                for task in self.tasks:
                    if task.get('done') or task.get('reminded') or not task.get('remind_at'):
                        continue
                    try:
                        remind_dt = datetime.fromisoformat(task['remind_at'])
                        seconds_until = (remind_dt - now).total_seconds()
                        if 0 <= seconds_until < 60:
                            task['reminded'] = True
                            task['remind_at'] = None
                            self.memory['tasks'] = self.tasks
                            self.save_memory()
                            msg = f"Sir, reminder: {task['description']}"
                            self.log(f"‚è∞ {msg}")
                            if not self.gaming_mode:
                                self.speak_with_piper(msg)
                            else:
                                self.notification_queue.append({
                                    'source': 'Reminder',
                                    'message': msg,
                                    'timestamp': datetime.now().isoformat(),
                                    'metadata': {}
                                })
                    except Exception:
                        pass
            except Exception as e:
                logger.error(f"Reminder scheduler error: {e}")

            # --- NEW: Idle-time alert for priority notifications ---
            try:
                is_idle = (time.time() - self.last_interaction_time) > IDLE_THRESHOLD
                if is_idle and not self.is_speaking and not self.gaming_mode:
                    with self.queue_lock:
                        # Find the first unannounced high-priority notification
                        priority_item = next((item for item in self.notification_queue if item.get('priority') == 'HIGH' and not item.get('announced')), None)
                        
                        if priority_item:
                            # Mark as announced to prevent re-triggering
                            priority_item['announced'] = True
                            
                            # Formulate and speak the prompt
                            short_key = priority_item.get('short_key', 'a notification')
                            sender = self.extract_sender_name(priority_item.get('metadata', {}).get('sender', 'an unknown source'))
                            
                            prompt = f"Sir, you have a priority email [{short_key}] from {sender}. Shall I display it?"
                            
                            # Reset idle timer by updating last interaction time. This prevents spamming alerts.
                            self.last_interaction_time = time.time()
                            
                            # Speak the prompt
                            self.log(f"üó£Ô∏è Idle Alert: {prompt}")
                            self.speak_with_piper(prompt)
                            
                            # This interaction should set a pending context, e.g. waiting for "yes" or "display it"
            except Exception as e:
                logger.error(f"Idle-time alert processing error: {e}")

            try:
                if self.notification_queue and not self.is_speaking:
                    logger.debug("Scheduler: processing notification queue")
                    self.process_notification_queue(context="idle")
            except Exception as e:
                logger.error(f"Notification queue processing error in scheduler: {e}")

            time.sleep(30)

    def handle_task_request(self, user_request):
        """Handle task / reminder creation, listing, completion, and recall.

        Examples:
          "Remind me to order dog food"
          "What's on my list?"
          "Mark the first task done"
          "Did I ever order dog food?"
        """
        import re
        text = user_request.lower()

        # --- LIST ---
        list_words = ["what's on my list", "show my tasks", "what tasks",
                      "list tasks", "pending tasks", "my reminders",
                      "show reminders", "what do i need to do",
                      "what have i got"]
        if any(w in text for w in list_words):
            task_text = self.list_tasks()
            reply = ("Here are your pending tasks:\n" + task_text
                     if task_text != "No pending tasks."
                     else "You have no pending tasks.")
            self.speak_with_piper(reply)
            self.add_to_context("User", user_request)
            self.add_to_context("Jarvis", reply)
            self.last_intent = "task"
            self.dashboard.push_focus("docs", "Task List", task_text)
            self.log_vault_action("tasks_listed", "Listed pending tasks")
            return

        # --- COMPLETE ---
        complete_words = ['done', 'complete', 'finished', 'mark',
                          'tick off', 'crossed off', 'check off']
        if any(w in text for w in complete_words):
            desc = self.mark_task_done(user_request)
            if desc:
                msg = f"Done. I've marked '{desc}' as complete."
                self.speak_with_piper(msg)
                self.add_to_context("User", user_request)
                self.add_to_context("Jarvis", msg)
                self.last_intent = "task"
                self.dashboard.push_focus("docs", "Task List", self.list_tasks())
            else:
                self.speak_with_piper(
                    "I couldn't find that task. "
                    "You can say the number or part of the description.")
            return

        # --- DID I / HAVE I (memory recall) ---
        recall_match = re.search(
            r'\b(?:did|have)\s+(?:i|you|we)\s+(?:ever\s+)?(.+?)(?:\?|$)',
            text)
        if recall_match:
            keyword = recall_match.group(1).strip()
            done_tasks = [t for t in self.tasks
                          if t.get('done') and keyword in t['description'].lower()]
            action_hits = self.memory_index.search_by_keyword(keyword, limit=3)
            if done_tasks:
                msg = f"Yes ‚Äî '{done_tasks[0]['description']}' was marked done."
            elif action_hits:
                a = action_hits[0]
                msg = (f"I logged this: {a.get('description', 'an action')} "
                       f"on {a.get('timestamp', '')[:10]}.")
            else:
                pending = [t for t in self.tasks
                           if keyword in t['description'].lower()]
                if pending:
                    msg = f"It's still on your list: {pending[0]['description']}"
                else:
                    msg = "I don't have any record of that, Sir."
            self.speak_with_piper(msg)
            self.add_to_context("User", user_request)
            self.add_to_context("Jarvis", msg)
            self.last_intent = "task"
            return

        # --- ADD / CREATE ---
        task_desc = None
        # "remind me to X", "remember to X", "don't forget to X"
        m = re.search(
            r'(?:remind(?:er)?\s+(?:me\s+)?(?:to\s+)?|remember\s+to\s+|'
            r'don\'t\s+forget\s+(?:to\s+)?|note\s+(?:to\s+)?(?:self\s+)?)'
            r'(.+?)(?:\s+(?:in\s+\d|\bat\b|\bon\b|tomorrow|tonight|this|next)|$)',
            user_request, re.IGNORECASE)
        if m:
            task_desc = m.group(1).strip()
        if not task_desc:
            # Simpler fallback: everything after "remind me"
            s = re.search(r'remind(?:er)?\s+(?:me\s+)?(?:to\s+)?(.+)',
                          user_request, re.IGNORECASE)
            if s:
                task_desc = s.group(1).strip()
        if not task_desc:
            task_desc = user_request.strip()

        remind_at, _ = self.parse_relative_datetime(user_request)
        self.add_task(task_desc, remind_at)

        if remind_at:
            time_str = remind_at.strftime('%A at %I:%M %p').lstrip('0')
            msg = f"Noted. I'll remind you to {task_desc} on {time_str}."
        else:
            msg = f"Added to your list: {task_desc}."

        self.speak_with_piper(msg)
        self.add_to_context("User", user_request)
        self.add_to_context("Jarvis", msg)
        self.last_intent = "task"
        self.dashboard.push_focus("docs", "Task List", self.list_tasks())

    def _handle_list_tasks(self, user_request):
        """Sub-handler for listing tasks."""
        task_text = self.list_tasks()
        reply = ("Here are your pending tasks:\n" + task_text
                 if task_text != "No pending tasks."
                 else "You have no pending tasks.")
        self.speak_with_piper(reply)
        self.add_to_context("User", user_request)
        self.add_to_context("Jarvis", reply)
        self.last_intent = "task"
        self.dashboard.push_focus("docs", "Task List", task_text)
        self.log_vault_action("tasks_listed", "Listed pending tasks")

    def _handle_complete_task(self, user_request):
        """Sub-handler for completing tasks."""
        desc = self.mark_task_done(user_request)
        if desc:
            msg = f"Done. I've marked '{desc}' as complete."
            self.speak_with_piper(msg)
            self.add_to_context("User", user_request)
            self.add_to_context("Jarvis", msg)
            self.last_intent = "task"
            self.dashboard.push_focus("docs", "Task List", self.list_tasks())
        else:
            self.speak_with_piper(
                "I couldn't find that task. "
                "You can say the number or part of the description.")

    def _handle_recall_task(self, user_request):
        """Sub-handler for recalling past tasks/actions."""
        text = user_request.lower()
        recall_match = re.search(
            r'\b(?:did|have)\s+(?:i|you|we)\s+(?:ever\s+)?(.+?)(?:\?|$)',
            text)
        if not recall_match: return # Should not happen if routed correctly

        keyword = recall_match.group(1).strip()
        done_tasks = [t for t in self.tasks
                      if t.get('done') and keyword in t['description'].lower()]
        action_hits = self.memory_index.search_by_keyword(keyword, limit=3)
        if done_tasks:
            msg = f"Yes ‚Äî '{done_tasks[0]['description']}' was marked done."
        elif action_hits:
            a = action_hits[0]
            msg = (f"I logged this: {a.get('description', 'an action')} "
                   f"on {a.get('timestamp', '')[:10]}.")
        else:
            pending = [t for t in self.tasks
                       if not t.get('done') and keyword in t['description'].lower()]
            if pending:
                msg = f"It's still on your list: {pending[0]['description']}"
            else:
                msg = "I don't have any record of that, Sir."
        self.speak_with_piper(msg)
        self.add_to_context("User", user_request)
        self.add_to_context("Jarvis", msg)
        self.last_intent = "task"

    def _handle_add_task(self, user_request):
        """Sub-handler for adding a new task."""
        task_desc = None
        m = re.search(
            r'(?:remind(?:er)?\s+(?:me\s+)?(?:to\s+)?|remember\s+to\s+|'
            r'don\'t\s+forget\s+(?:to\s+)?|note\s+(?:to\s+)?(?:self\s+)?)'
            r'(.+?)(?:\s+(?:in\s+\d|\bat\b|\bon\b|tomorrow|tonight|this|next)|$)',
            user_request, re.IGNORECASE)
        if m:
            task_desc = m.group(1).strip()
        if not task_desc:
            s = re.search(r'remind(?:er)?\s+(?:me\s+)?(?:to\s+)?(.+)',
                          user_request, re.IGNORECASE)
            if s:
                task_desc = s.group(1).strip()
        if not task_desc:
            task_desc = user_request.strip()

        remind_at, _ = self.parse_relative_datetime(user_request)
        self.add_task(task_desc, remind_at)

        if remind_at:
            time_str = remind_at.strftime('%A at %I:%M %p').lstrip('0')
            msg = f"Noted. I'll remind you to {task_desc} on {time_str}."
        else:
            msg = f"Added to your list: {task_desc}."

        self.speak_with_piper(msg)
        self.add_to_context("User", user_request)
        self.add_to_context("Jarvis", msg)
        self.last_intent = "task"
        self.dashboard.push_focus("docs", "Task List", self.list_tasks())

    def handle_task_request(self, user_request):
        """
        Refactored task handler. Routes to sub-handlers for specific actions.
        """
        text = user_request.lower()

        # --- LIST ---
        list_words = ["what's on my list", "show my tasks", "what tasks",
                      "list tasks", "pending tasks", "my reminders",
                      "show reminders", "what do i need to do",
                      "what have i got"]
        if any(w in text for w in list_words):
            self._handle_list_tasks(user_request)
            return

        # --- COMPLETE ---
        complete_words = ['done', 'complete', 'finished', 'mark',
                          'tick off', 'crossed off', 'check off']
        if any(w in text for w in complete_words):
            self._handle_complete_task(user_request)
            return

        # --- RECALL ---
        if re.search(r'\b(?:did|have)\s+(?:i|you|we)\s+(?:ever\s+)?', text):
            self._handle_recall_task(user_request)
            return

        # --- ADD / CREATE (default action) ---
        self._handle_add_task(user_request)

    # ‚îÄ‚îÄ Long-term memory management ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def _find_superseded_fact(self, new_fact: str) -> int:
        """Return the index of an existing fact that new_fact supersedes, or -1.

        Uses two passes:
        1. Anchor-noun match ‚Äî facts sharing a topic anchor (car, job, health‚Ä¶)
           are considered to be about the same subject ‚Üí definite replacement.
        2. Jaccard word-overlap fallback (threshold ‚â• 0.40) ‚Äî catches cases
           where the anchor vocabulary doesn't cover the topic.
        """
        facts = self.memory.get('facts', [])
        if not facts:
            return -1

        stopwords = {
            'the', 'a', 'an', 'is', 'are', 'was', 'were', 'has', 'have', 'had',
            'in', 'on', 'at', 'to', 'for', 'of', 'and', 'or', 'but', 'i', 'my',
            'me', 'he', 'she', 'they', 'it', 'his', 'her', 'its', 'your', 'our',
            'spencer', 's', 'now', 'new', 'still', 'also', 'just', 'that', 'this',
        }

        def sig_words(text):
            return set(re.sub(r'[^\w\s]', '', text.lower()).split()) - stopwords

        new_sig = sig_words(new_fact)
        new_anchors = new_sig & _MEMORY_ANCHORS

        best_idx, best_score = -1, 0.0

        for idx, fact in enumerate(facts):
            fact_sig = sig_words(fact)
            fact_anchors = fact_sig & _MEMORY_ANCHORS

            # Pass 1: shared anchor noun ‚Üí same subject, replace immediately
            if new_anchors and fact_anchors and (new_anchors & fact_anchors):
                logger.debug(
                    "Memory anchor match: '%s' ‚Üî '%s' (anchors: %s)",
                    new_fact[:60], fact[:60], new_anchors & fact_anchors)
                return idx

            # Pass 2: Jaccard fallback
            if new_sig and fact_sig:
                score = len(new_sig & fact_sig) / len(new_sig | fact_sig)
                if score > best_score:
                    best_score = score
                    best_idx = idx

        if best_score >= 0.40:
            logger.debug(
                "Memory Jaccard match (%.2f): '%s' ‚Üî '%s'",
                best_score, new_fact[:60], facts[best_idx][:60])
            return best_idx

        return -1

    def replace_or_add_fact(self, new_fact: str, delete: bool = False) -> str:
        """Update long-term memory with a new or corrected fact.

        Args:
            new_fact: The fact text to store (or the fact to delete if delete=True).
            delete:   If True, remove the matching fact instead of replacing it.

        Returns:
            Human-readable description of what changed.
        """
        facts = self.memory.setdefault('facts', [])
        idx = self._find_superseded_fact(new_fact)

        if delete:
            if idx >= 0:
                removed = facts.pop(idx)
                self.save_memory()
                logger.info("Memory: deleted fact ‚Äî %s", removed)
                return f"Removed: '{removed}'"
            logger.info("Memory: no matching fact found to delete for: %s", new_fact)
            return "no_match"

        if idx >= 0:
            old = facts[idx]
            facts[idx] = new_fact
            self.save_memory()
            logger.info("Memory: replaced\n  OLD: %s\n  NEW: %s", old, new_fact)
            return f"replaced::{old}"
        else:
            facts.append(new_fact)
            self.save_memory()
            logger.info("Memory: added new fact ‚Äî %s", new_fact)
            return "added"

    def handle_learn_fact(self, user_request: str):
        """Handle memory update / forget requests.

        Examples:
            "Remember that I now drive a BMW"
            "Update your memory: I moved to Maidstone"
            "Forget that I have a Ford Focus"
            "That's no longer true ‚Äî I don't work at Acme anymore"
        """
        text_lower = user_request.lower()

        # Detect forget/delete intent
        is_delete = any(kw in text_lower for kw in [
            "forget that", "forget i ", "forget my ", "remove from memory",
            "delete that", "no longer true", "not true anymore",
            "remove that fact", "that's wrong",
        ])

        # Extract fact text by stripping command preamble
        fact_text = user_request
        preambles = [
            r'(?:please\s+)?(?:remember|note|update\s+your\s+memory|store|keep\s+in\s+mind)[\s:,]+(?:that\s+)?',
            r'(?:please\s+)?(?:forget|remove|delete)[\s:,]+(?:that\s+)?',
            r'(?:update|correction|note)[\s:,]+',
            r"that'?s\s+(?:no\s+longer\s+true|wrong|not\s+right)[,\s\-]*(?:i\s+)?",
            r'by\s+the\s+way[,\s]+',
        ]
        for pattern in preambles:
            cleaned = re.sub(pattern, '', fact_text, flags=re.IGNORECASE).strip()
            if cleaned and cleaned != fact_text:
                fact_text = cleaned
                break

        # Capitalise: prepend "Spencer" if it starts with a verb/lowercase pronoun
        fact_text = fact_text.rstrip('.!?').strip()
        if fact_text and not fact_text.lower().startswith('spencer') \
                and not fact_text.lower().startswith('jarvis'):
            fact_text = 'Spencer ' + fact_text[0].lower() + fact_text[1:]

        result = self.replace_or_add_fact(fact_text, delete=is_delete)

        # Build spoken confirmation
        if is_delete:
            if result == "no_match":
                msg = "I couldn't find a matching memory to remove."
            else:
                msg = "Done. I've removed that from my memory."
        elif result.startswith("replaced::"):
            msg = "Memory updated. I've replaced the old record with the new one."
        else:
            msg = "Got it. I've made a note of that."

        self.speak_with_piper(msg)
        self.add_to_context("User", user_request)
        self.add_to_context("Jarvis", msg)
        self.last_intent = "memory"

        # Show current fact list in focus window
        facts_display = "\n".join(
            f"‚Ä¢ {f}" for f in self.memory.get('facts', []))
        self.dashboard.push_focus("docs", "Memory ‚Äî Known Facts", facts_display)
        self.log_vault_action(
            "memory_updated",
            f"Fact {'deleted' if is_delete else 'learned'}: {fact_text}")
    
    # --- GMAIL EMAIL TOOLS ---
    def search_emails(self, query):
        """Search Gmail for emails matching query (e.g., 'from:john@example.com', 'subject:proposal').
        
        Args:
            query: Gmail search query (supports Gmail operators: from:, subject:, to:, etc.)
        
        Returns:
            List of email dicts with sender, subject, snippet, unique_id
        """
        try:
            creds = get_google_creds()
            service = build('gmail', 'v1', credentials=creds)
            
            # Search for matching emails
            results = service.users().messages().list(userId='me', q=query, maxResults=5).execute()
            messages = results.get('messages', [])
            
            if not messages:
                logger.info(f"No emails found for query: {query}")
                return []
            
            # Fetch full email details for each result
            emails = []
            for msg in messages:
                try:
                    msg_data = service.users().messages().get(userId='me', id=msg['id'], format='full').execute()
                    headers = msg_data['payload']['headers']
                    
                    email_obj = {
                        'id': msg['id'],
                        'sender': next((h['value'] for h in headers if h['name'] == 'From'), 'Unknown'),
                        'subject': next((h['value'] for h in headers if h['name'] == 'Subject'), 'No Subject'),
                        'snippet': msg_data.get('snippet', '')[:200]  # First 200 chars
                    }
                    emails.append(email_obj)
                except Exception as e:
                    logger.warning(f"Failed to fetch email details: {e}")
                    continue
            
            logger.info(f"‚úì Found {len(emails)} email(s) matching: {query}")
            return emails
            
        except Exception as e:
            logger.error(f"Email search error: {e}")
            self.log(f"‚ùå Email search failed: {e}")
            return []
    
    def get_recent_emails(self, limit=5):
        """Get the most recent emails from inbox.
        
        Args:
            limit: Number of recent emails to fetch (default 5)
        
        Returns:
            List of email dicts with sender, subject, snippet, unique_id
        """
        try:
            creds = get_google_creds()
            service = build('gmail', 'v1', credentials=creds)
            
            # Get recent emails
            results = service.users().messages().list(userId='me', maxResults=limit).execute()
            messages = results.get('messages', [])
            
            emails = []
            for msg in messages:
                try:
                    msg_data = service.users().messages().get(userId='me', id=msg['id'], format='full').execute()
                    headers = msg_data['payload']['headers']
                    
                    email_obj = {
                        'id': msg['id'],
                        'sender': next((h['value'] for h in headers if h['name'] == 'From'), 'Unknown'),
                        'subject': next((h['value'] for h in headers if h['name'] == 'Subject'), 'No Subject'),
                        'snippet': msg_data.get('snippet', '')[:200],
                        'internal_date': msg_data.get('internalDate', '')
                    }
                    emails.append(email_obj)
                except Exception as e:
                    logger.warning(f"Failed to fetch email details: {e}")
                    continue
            
            logger.info(f"‚úì Retrieved {len(emails)} recent email(s)")
            return emails
            
        except Exception as e:
            logger.error(f"Failed to get recent emails: {e}")
            self.log(f"‚ùå Failed to get recent emails: {e}")
            return []
    
    def send_email(self, to_address, subject, body):
        """Send an email via Gmail.
        
        Args:
            to_address: Recipient email address
            subject: Email subject line
            body: Email body text
        
        Returns:
            True if successful, False otherwise
        """
        try:
            import base64
            from email.mime.text import MIMEText
            
            creds = get_google_creds()
            service = build('gmail', 'v1', credentials=creds)
            
            # Create message
            message = MIMEText(body)
            message['to'] = to_address
            message['subject'] = subject
            
            # Encode to base64
            raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode()
            
            # Send
            send_message = {'raw': raw_message}
            result = service.users().messages().send(userId='me', body=send_message).execute()
            
            logger.info(f"‚úì Email sent to {to_address}: {subject}")
            self.log(f"‚úì Email sent to {to_address}")
            return True
            
        except Exception as e:
            logger.error(f"Email send error: {e}")
            self.log(f"‚ùå Failed to send email: {e}")
            return False
    
    def reply_to_email(self, message_id, reply_text):
        """Reply to an email thread.
        
        Args:
            message_id: Gmail message ID to reply to
            reply_text: Reply text body
        
        Returns:
            True if successful, False otherwise
        """
        try:
            import base64
            from email.mime.text import MIMEText
            
            creds = get_google_creds()
            service = build('gmail', 'v1', credentials=creds)
            
            # Get original message to extract headers
            original_msg = service.users().messages().get(userId='me', id=message_id, format='full').execute()
            headers = original_msg['payload']['headers']
            
            # Extract original subject and recipients
            subject = next((h['value'] for h in headers if h['name'] == 'Subject'), 'No Subject')
            from_email = next((h['value'] for h in headers if h['name'] == 'From'), OWNER_EMAIL)
            
            # Ensure Re: prefix
            if not subject.lower().startswith('re:'):
                subject = f"Re: {subject}"
            
            # Create reply message
            message = MIMEText(reply_text)
            message['to'] = from_email
            message['subject'] = subject
            message['In-Reply-To'] = original_msg.get('headers', [])[0].get('value', '')
            
            # Send as reply
            raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode()
            send_message = {
                'raw': raw_message,
                'threadId': original_msg.get('threadId', '')
            }
            
            result = service.users().messages().send(userId='me', body=send_message).execute()
            logger.info(f"‚úì Reply sent to email thread")
            self.log(f"‚úì Reply sent")
            return True
            
        except Exception as e:
            logger.error(f"Email reply error: {e}")
            self.log(f"‚ùå Failed to send reply: {e}")
            return False

    def check_piper_installation(self):
        """Check if Piper TTS is available."""
        try:
            self.piper_exe = self.resolve_piper_executable()
            if not self.piper_exe:
                logger.warning("‚ö†Ô∏è  Piper TTS not found - wake word acknowledgment disabled")
                return False

            result = subprocess.run(
                [self.piper_exe, "--version"],
                capture_output=True,
                timeout=3
            )
            logger.info("‚úì Piper TTS is available")
            return True
        except (FileNotFoundError, subprocess.TimeoutExpired):
            logger.warning("‚ö†Ô∏è  Piper TTS not found - wake word acknowledgment disabled")
            return False

    def resolve_piper_executable(self):
        """Resolve Piper executable path from config, PATH, or local venv."""
        candidates = []

        config_path = config_dict.get("piper_exe")
        if config_path:
            candidates.append(config_path)

        candidates.append(shutil.which("piper"))

        project_root = os.path.dirname(__file__)
        candidates.extend([
            os.path.join(project_root, ".venv", "Scripts", "piper.exe"),
            os.path.join(project_root, "venv", "Scripts", "piper.exe"),
        ])

        for path in candidates:
            if path and os.path.exists(path):
                logger.info(f"‚úì Piper executable found: {path}")
                return path

        return None
    
    def generate_yes_audio(self):
        """Generate the 'yes' audio file if it doesn't exist."""
        if not self.piper_available:
            logger.warning("Skipping yes.wav generation - Piper not available")
            self.log("‚ö†Ô∏è  Piper TTS not installed - using beep for wake word acknowledgment")
            self.log("   Install Piper for voice: https://github.com/rhasspy/piper/releases")
            return
        
        if os.path.exists(self.yes_audio_path):
            logger.info(f"‚úì Wake word audio asset found: {self.yes_audio_path}")
            return
        
        try:
            logger.info("Generating wake word acknowledgment audio...")
            self.log("üéµ Generating 'Yes?' audio with Jarvis voice...")
            model_path = os.path.join(os.path.dirname(__file__), "jarvis-high.onnx")
            result = subprocess.run(
                [self.piper_exe, "-m", model_path, "-f", self.yes_audio_path],
                input="Yes?".encode(),
                capture_output=True,
                timeout=10
            )
            
            if result.returncode == 0:
                logger.info(f"‚úì Created {self.yes_audio_path} with Jarvis voice")
                self.log(f"‚úì Audio asset created: {self.yes_audio_path}")
            else:
                logger.error(f"Failed to generate yes.wav: {result.stderr.decode()}")
                self.log("‚ö†Ô∏è  Audio generation failed - will use beep fallback")
        except Exception as e:
            logger.error(f"Error generating yes.wav: {e}")
            self.log(f"‚ö†Ô∏è  Audio generation error - will use beep fallback")
    
    def play_yes_audio(self):
        """Play the pre-generated 'yes' audio file or beep as fallback."""
        if os.path.exists(self.yes_audio_path):
            try:
                # Play using PowerShell SoundPlayer (fast, non-blocking)
                subprocess.Popen(
                    ["powershell", "-c", f"(New-Object Media.SoundPlayer '{os.path.abspath(self.yes_audio_path)}').PlaySync();"],
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL
                )
                logger.debug("Playing wake word acknowledgment")
            except Exception as e:
                logger.error(f"Error playing yes.wav: {e}")
                self.play_beep_fallback()
        else:
            # Fallback to system beep if yes.wav doesn't exist
            logger.warning("yes.wav not found - using beep fallback")
            self.play_beep_fallback()
    
    def play_beep_fallback(self):
        """Play a system beep as fallback when yes.wav is not available."""
        try:
            # Play a pleasant double beep using PowerShell
            subprocess.Popen(
                ["powershell", "-c", "[console]::beep(800,150); [console]::beep(1000,150)"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            logger.debug("Played beep fallback")
        except Exception as e:
            logger.error(f"Beep fallback failed: {e}")
    
    def listen_and_transcribe(self, duration=None):
        """Capture audio with VAD and transcribe with Whisper (duration parameter kept for compatibility but ignored)."""
        if self.recorder is None:
            logger.error("Recorder not available for transcription")
            return None
        
        try:
            logger.info("Listening with VAD (waiting for speech)...")
            self.status_var.set("Status: Listening...")
            self.log("üé§ Listening for your command...")
            
            # Update dashboard: listening mode
            if hasattr(self, 'dashboard'):
                self.dashboard.push_state(mode="listening")
            
            # VAD-based audio capture
            speech_frames = []
            is_speaking = False
            silence_counter = 0
            speech_counter = 0
            
            frames_per_second = self.porcupine.sample_rate / self.porcupine.frame_length
            silence_frames = int(self.silence_duration * frames_per_second)
            min_speech_frames = int(self.min_speech_duration * frames_per_second)
            
            # Maximum listening time (safety limit)
            max_listen_time = 30
            frames_captured = 0
            max_frames = int(max_listen_time * frames_per_second)
            
            while frames_captured < max_frames:
                # Don't listen while speaking (avoid transcribing own voice)
                if not self.is_listening or self.gaming_mode or self.is_speaking:
                    logger.info("Listening interrupted")
                    return None
                
                pcm = self.recorder.read()
                frames_captured += 1
                
                # Calculate speech energy
                energy = self.detect_speech_energy(pcm)
                
                if energy > self.vad_threshold:
                    # Speech detected
                    if not is_speaking:
                        logger.debug(f"Speech started (energy: {energy:.0f})")
                        self.status_var.set("Status: üé§ Recording...")
                        is_speaking = True
                        speech_counter = 0
                    
                    speech_frames.extend(pcm)
                    speech_counter += 1
                    silence_counter = 0
                    
                    # Update progress
                    if speech_counter % 25 == 0:
                        elapsed = (speech_counter * self.porcupine.frame_length) / self.porcupine.sample_rate
                        self.status_var.set(f"Status: Recording ({elapsed:.1f}s)...")
                    
                elif is_speaking:
                    # Silence during speech
                    silence_counter += 1
                    speech_frames.extend(pcm)
                    
                    if silence_counter >= silence_frames:
                        # End of speech detected
                        if speech_counter >= min_speech_frames:
                            logger.info(f"Speech ended (captured {speech_counter} frames, {silence_counter} silence frames)")
                            break
                        else:
                            # Too short, reset
                            logger.debug("Speech too short, resetting")
                            is_speaking = False
                            speech_frames = []
                            silence_counter = 0
                            speech_counter = 0
                            self.status_var.set("Status: Listening...")
            
            if not speech_frames or speech_counter < min_speech_frames:
                logger.warning("No valid speech detected")
                self.log("‚ö†Ô∏è  No speech detected")
                return None
            
            logger.info(f"Captured {len(speech_frames)} audio samples via VAD")
            
            # Convert to numpy array and normalize
            audio_data = np.array(speech_frames, dtype=np.int16)
            
            # Save to temporary WAV file for Whisper
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_wav:
                temp_path = temp_wav.name
            
            with wave.open(temp_path, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)  # 16-bit
                wf.setframerate(self.porcupine.sample_rate)
                wf.writeframes(audio_data.tobytes())
            
            logger.debug(f"Audio saved to {temp_path}")
            
            # Transcribe with Whisper
            self.status_var.set("Status: Transcribing...")
            self.log("üìù Transcribing...")
            logger.info("Starting Whisper transcription...")
            
            if hasattr(self, 'dashboard'): self.dashboard.set_transcribing_status(True)
            result = self.stt_model.transcribe(temp_path, language='en')
            if hasattr(self, 'dashboard'): self.dashboard.set_transcribing_status(False)

            text = result['text'].strip()
            
            # Clean up temp file
            try:
                os.unlink(temp_path)
            except OSError as e:
                logger.debug("Whisper temp cleanup skip: %s", e)

            if text:
                logger.info(f"Transcribed: {text}")
                return text
            else:
                logger.warning("No speech detected in transcription")
                self.log("‚ö†Ô∏è  No speech detected")
                return None
                
        except Exception as e:
            logger.error(f"Transcription error: {e}", exc_info=True)
            self.log(f"Transcription Error: {e}")
            return None
    
    def detect_speech_energy(self, audio_chunk):
        """Simple energy-based speech detection."""
        if len(audio_chunk) == 0:
            return 0
        # Calculate RMS energy with safe conversion
        audio_array = np.array(audio_chunk, dtype=np.float32)
        mean_square = np.mean(audio_array**2)
        # Ensure non-negative and valid
        if mean_square < 0 or np.isnan(mean_square):
            return 0
        energy = np.sqrt(mean_square)
        return energy
    
    def continuous_listen_and_transcribe(self):
        """Continuous listening for conversation mode - captures when speech detected."""
        if self.recorder is None:
            logger.error("Recorder not available for continuous listening")
            return None
        
        try:
            logger.info("Continuous listening mode active...")
            
            # Buffer to accumulate audio
            audio_buffer = []
            speech_frames = []
            is_speaking = False
            silence_counter = 0
            speech_counter = 0
            
            frames_per_second = self.porcupine.sample_rate / self.porcupine.frame_length
            silence_frames = int(self.silence_duration * frames_per_second)
            min_speech_frames = int(self.min_speech_duration * frames_per_second)
            
            # Monitor for speech in a rolling window
            max_listen_time = 30  # Maximum 30 seconds per conversation turn
            frames_captured = 0
            max_frames = int(max_listen_time * frames_per_second)
            
            while frames_captured < max_frames:
                # Don't listen while speaking, gaming, or mic muted
                if (not self.is_listening or self.gaming_mode
                        or not self.conversation_mode or self.is_speaking
                        or self.mic_muted):
                    logger.info("Continuous listening interrupted")
                    return None
                
                pcm = self.recorder.read()
                frames_captured += 1
                
                # Calculate speech energy
                energy = self.detect_speech_energy(pcm)
                
                if energy > self.vad_threshold:
                    # Speech detected
                    if not is_speaking:
                        logger.debug(f"Speech started (energy: {energy:.0f})")
                        self.status_var.set("Status: üé§ Listening...")
                        is_speaking = True
                        speech_counter = 0
                    
                    speech_frames.extend(pcm)
                    speech_counter += 1
                    silence_counter = 0
                    
                elif is_speaking:
                    # Silence during speech
                    silence_counter += 1
                    speech_frames.extend(pcm)
                    
                    if silence_counter >= silence_frames:
                        # End of speech detected
                        if speech_counter >= min_speech_frames:
                            logger.info(f"Speech ended ({speech_counter} frames, {silence_counter} silence frames)")
                            break
                        else:
                            # Too short, reset
                            logger.debug("Speech too short, resetting")
                            is_speaking = False
                            speech_frames = []
                            silence_counter = 0
                            speech_counter = 0
                
                # Update status periodically
                if frames_captured % 50 == 0:
                    if not is_speaking:
                        self.status_var.set("Status: üí¨ Conversation Mode - Speak freely...")
            
            if not speech_frames or speech_counter < min_speech_frames:
                logger.debug("No valid speech detected")
                return None
            
            logger.info(f"Processing {len(speech_frames)} audio samples")
            
            # Convert to numpy array
            audio_data = np.array(speech_frames, dtype=np.int16)
            
            # Save to temporary WAV file
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_wav:
                temp_path = temp_wav.name
            
            with wave.open(temp_path, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(self.porcupine.sample_rate)
                wf.writeframes(audio_data.tobytes())
            
            # Transcribe with Whisper
            self.status_var.set("Status: üìù Transcribing...")
            logger.info("Transcribing continuous speech...")

            if hasattr(self, 'dashboard'): self.dashboard.set_transcribing_status(True)
            result = self.stt_model.transcribe(temp_path, language='en')
            if hasattr(self, 'dashboard'): self.dashboard.set_transcribing_status(False)
            text = result['text'].strip()
            
            # Clean up
            try:
                os.unlink(temp_path)
            except OSError as e:
                logger.debug("Whisper continuous temp cleanup skip: %s", e)

            if text:
                logger.info(f"Transcribed (continuous): {text}")
                return text
            else:
                return None
                
        except Exception as e:
            logger.error(f"Continuous listening error: {e}", exc_info=True)
            return None

    @staticmethod
    @functools.lru_cache(maxsize=256)
    def extract_sender_name(sender_str):
        """Extract just the name from 'Name <email@domain>' format for speech.
        Cached: reduces repeated parsing of sender strings.
        """
        if '<' in sender_str and '>' in sender_str:
            # Extract name part: "John Doe <john@example.com>" -> "John Doe"
            name = sender_str.split('<')[0].strip()
            return name if name else sender_str.replace('<', '').replace('>', '').replace('@', ' at ')
        # Remove @ and replace with 'at' for readability
        return sender_str.replace('@', ' at ').replace('<', '').replace('>', '')
    
    @staticmethod
    def sanitize_for_speech(text):
        """Remove/replace characters that shouldn't be spoken."""
        # Strip code fences (triple-backtick blocks) ‚Äî replace entirely with placeholder
        text = re.sub(r'```[\w]*\n.*?```', 'code block omitted', text, flags=re.DOTALL)
        # Strip inline code
        text = re.sub(r'`[^`\n]+`', '', text)

        # Replace symbols with their spoken equivalents
        text = text.replace('¬∞', ' degrees ')  # Degree symbol ‚Üí "degrees"
        
        # Replace email-style characters
        text = text.replace('<', '')  # Remove angle brackets
        text = text.replace('>', '')
        text = text.replace('@', ' at ')  # Replace @ with 'at'
        
        # Remove markdown characters
        text = text.replace('*', '')  # Remove asterisks
        text = text.replace('#', '')  # Remove hash symbols
        text = text.replace('_', '')  # Remove underscores
        text = text.replace('`', '')  # Remove backticks
        text = text.replace('~', '')  # Remove tildes
        text = text.replace('|', '')  # Remove pipes
        text = text.replace('[', '')  # Remove brackets
        text = text.replace(']', '')
        text = text.replace('{', '')  # Remove braces
        text = text.replace('}', '')
        
        # Remove multiple spaces
        text = ' '.join(text.split())
        return text
    
    def speak_with_piper(self, text):
        """Use Piper TTS to speak longer responses (with barge-in support).
        Uses a lock to prevent concurrent audio playback (speaking over self).
        """
        # Gaming mode silences all output ‚Äî mic AND speaker are effectively paused
        if self.gaming_mode:
            logger.debug("speak_with_piper suppressed: gaming mode active")
            return

        with self.speak_lock:  # Serialize all speech generation
            # Log happens in process_conversation to avoid duplicate entries
            
            if not self.piper_available:
                logger.warning("Piper TTS not available - cannot speak response")
                self.log(f"üîá TTS unavailable: {text}")
                return

            if not getattr(self, "piper_exe", None):
                self.piper_exe = self.resolve_piper_executable()
                if not self.piper_exe:
                    logger.warning("Piper executable not found - cannot speak response")
                    self.log(f"üîá TTS unavailable (no piper.exe): {text}")
                    return
            
            try:
                # Clean text for speech
                clean_text = self.sanitize_for_speech(text)
                
                logger.debug(f"Speaking with Piper: {clean_text[:50]}...")
                
                # Create temporary WAV file
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_wav:
                    temp_path = temp_wav.name
                
                # Generate speech with Piper using local model
                model_path = os.path.join(os.path.dirname(__file__), "jarvis-high.onnx")
                result = subprocess.run(
                    [self.piper_exe, "-m", model_path, "-f", temp_path],
                    input=clean_text.encode(),
                    capture_output=True,
                    timeout=60
                )
                
                if result.returncode == 0:
                    # Set speaking flag and start VAD monitor for barge-in
                    self.is_speaking = True
                    self.interrupt_requested = False
                    self.start_vad_monitor()
                    
                    # Update dashboard: speaking mode
                    if hasattr(self, 'dashboard'):
                        self.dashboard.push_state(mode="speaking")
                    
                    # Play the audio file using Windows - check for interruptions
                    self.current_tts_process = subprocess.Popen(
                        ["powershell", "-c", f"(New-Object Media.SoundPlayer '{temp_path}').PlaySync();"],
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL
                    )
                    
                    # Monitor for barge-in while playing
                    while self.current_tts_process.poll() is None:
                        if self.interrupt_requested:
                            logger.warning("Barge-in: Stopping speech immediately")
                            self.current_tts_process.kill()
                            self.log("üõë Interrupted - Listening, Sir")
                            break
                        time.sleep(0.05)
                    
                    # Clean up
                    self.is_speaking = False
                    self.stop_vad_monitor()
                    self.current_tts_process = None
                    
                    # If interrupted, skip the echo fix delay
                    if not self.interrupt_requested:
                        logger.debug("Audio played successfully")
                        # Echo fix: Wait for speaker to settle before resuming listening
                        time.sleep(0.8)
                    else:
                        # Reset interrupt flag for next speak
                        self.interrupt_requested = False
                        # Brief pause before listening again
                        time.sleep(0.2)
                        
                else:
                    logger.warning(f"Piper returned error code {result.returncode}")
                    stderr_text = result.stderr.decode(errors="ignore").strip()
                    if stderr_text:
                        logger.debug(f"Piper stderr: {stderr_text}")
                        self.log(f"üîá TTS failed (piper): {stderr_text}")
                    else:
                        self.log(f"üîá TTS failed: {text}")
                
                # Clean up temp file
                try:
                    os.unlink(temp_path)
                except OSError as e:
                    logger.debug("Piper temp cleanup skip: %s", e)

            except Exception as e:
                self.log(f"Piper TTS Error: {e}")
                logger.error(f"Piper TTS failed: {e}", exc_info=True)
            finally:
                # Ensure flags are reset
                self.is_speaking = False
                self.stop_vad_monitor()
                self.current_tts_process = None
                
                # Update dashboard: back to idle
                if hasattr(self, 'dashboard'):
                    self.dashboard.push_state(mode="idle")
    def _route_by_context(self, raw_text, text_lower):
        """Context-aware follow-up routing based on last known intent.

        Returns True if the input was fully handled (caller should return).
        """
        if not self.last_intent:
            return False

        # Email follow-ups ‚Äî "reply to that" without the word "email"
        if self.last_intent == "email":
            if (any(w in text_lower for w in ["reply", "respond", "answer"])
                    and "email" not in text_lower
                    and "mail" not in text_lower):
                self.handle_email_reply_request(raw_text)
                return True
            if any(w in text_lower for w in [
                    "archive", "handled", "bin", "trash",
                    "delete it", "delete that"]):
                self.handle_email_management_request(raw_text)
                return True

        # Calendar follow-ups ‚Äî "move the first one", "cancel that"
        if self.last_intent == "calendar":
            if (any(w in text_lower for w in [
                    "move", "reschedule", "cancel", "delete",
                    "first", "second", "third"])
                    and self.last_calendar_events):
                self.handle_calendar_action(raw_text)
                return True
            # Pending calendar event waiting for a time
            if self.pending_calendar_title:
                start_dt, _ = self.parse_relative_datetime(raw_text)
                if start_dt:
                    return self.check_pending_confirmation(raw_text)

        # Task follow-ups
        if self.last_intent == "task":
            if any(w in text_lower for w in [
                    "done", "complete", "finished", "mark",
                    "add another", "remind me"]):
                self.handle_task_request(raw_text)
                return True

        # Optimization follow-ups ‚Äî "display it", "show the file on screen", "put it up"
        if self.last_intent == "optimization":
            if any(w in text_lower for w in ["display", "put on", "show on"]):
                self.handle_report_retrieval(raw_text)
                return True
            if (any(w in text_lower for w in ["show", "open", "view"])
                    and any(w in text_lower for w in [
                        "document", "doc", "file", "report", "result", "it", "that"])):
                self.handle_report_retrieval(raw_text)
                return True

        # Search follow-ups
        if self.last_intent == "search":
            logger.debug("Context route: last_intent is 'search'. Checking for confirmation.")
            # If user confirms, re-run the last search.
            if any(w in text_lower for w in ["yes", "yeah", "yep", "go ahead", "sure", "please", "search", "website"]):
                if self.last_search_query:
                    logger.debug(f"Context route: Confirmation found. Re-running last search for '{self.last_search_query}'.")
                    self.log(f"Re-running previous search for '{self.last_search_query}' based on confirmation.")
                    # We pass the original query text to preserve it for the summary prompt
                    self.handle_web_search(self.last_search_query)
                    return True # Handled.
                else:
                    logger.warning("Context route: Confirmation for search detected, but no last_search_query was stored.")
                    self.speak_with_piper("I'm sorry, I don't recall what the last search was. Please ask again.")
                    return True

        return False

    def _handle_contextual_command(self, raw_text: str) -> bool:
        """
        Contextual Resolver: Handles commands targeting a short-key (e.g., "open wr1").
        Returns True if a command was found and handled, False otherwise.
        """
        # Regex to find an action and a short-key alias
        # Supports single-letter types (e,d,c,h,q) and 'wr' for web results
        match = re.search(
            r'^(?:open|show|display|summarise|summarize|analyse|analyze|reply to|dig deeper into|go to)\s+([ewdchq]r?\d+)$',
            raw_text.lower().strip()
        )

        if not match:
            return False

        action_verb = match.group(0).split(' ')[0] # e.g., "open", "summarize", "dig"
        short_alias = match.group(1)
        item = self.session_context.get_item(short_alias)

        if not item:
            logger.warning(f"Contextual command for '{short_alias}' but item not in session context.")
            return False # Let it fall through to LLM which might have context

        logger.info(f"Contextual command resolved: '{raw_text}' -> item '{short_alias}'")
        item_type = item.get('type')
        metadata = item.get('metadata', {})

        # --- NEW: Deep Dig Workflow ---
        if 'dig' in action_verb and item_type == 'w':
            self.handle_deep_dig(item)
            return True

        # --- Delegate to appropriate handler based on type ---
        if item_type == 'w': # Web Result
            url = metadata.get('url')
            if url:
                self.log(f"Opening web result {short_alias}: {url}")
                import webbrowser
                webbrowser.open(url)
                self.speak_with_piper(f"Opening {item.get('label', 'that link')}.")
                return True

        elif item_type == 'e': # Email
            self.speak_with_piper(f"Bringing up email {short_alias} from {item.get('label', 'that sender')}.")
            self.dashboard.push_focus("email", f"Email: {item.get('label')}", f"Content for email ID {metadata.get('id')} would be displayed here.")
            return True

        elif item_type == 'd': # Document (from deep dig)
            self.speak_with_piper(f"Displaying the analysis for {short_alias}.")
            self.dashboard.push_focus(
                "docs", 
                f"Analysis: {item.get('label', 'document')}", 
                f"Source: {metadata.get('source_url', 'N/A')}\n\n---\n\n{metadata.get('summary', 'No summary available.')}"
            )
            return True

        self.speak_with_piper(f"I'm not sure how to handle that action for {short_alias} yet.")
        return True # We recognized it, even if we can't act on it fully.

    def process_conversation(self, raw_text):
        """The main entry point for processing a user's voice command."""
        logger.debug(f"Processing conversation: {raw_text}")
        self.log(f"User: {raw_text}")

        try:
            # ‚îÄ‚îÄ STEP 1: Pending confirmations (e.g., "send email?") ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if self.check_pending_confirmation(raw_text):
                return

            # --- NEW: Step 2: Contextual Command Resolution (e.g., "summarize wr1") ---
            if self._handle_contextual_command(raw_text):
                return

            # --- If not a contextual command, it's a new query. Clear the session. ---
            self.session_context.clear()
            if hasattr(self, 'dashboard'):
                self.dashboard.update_ticker([]) # Clear the ticker tape

            # ‚îÄ‚îÄ STEP 3: Legacy Context-aware follow-ups (e.g., "archive that") ‚îÄ‚îÄ
            if self._route_by_context(raw_text, raw_text.lower()):
                return

            # ‚îÄ‚îÄ STEP 4: Score and route to the best intent handler ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            intent, score, details = self.route_intent(raw_text)

            if intent == "AMBIGUOUS":
                self.ask_for_clarification(raw_text, details['ambiguous_intents'])
            elif intent and intent != "LLM_BRAIN":
                handler = getattr(self, INTENTS[intent]['handler'])
                handler(raw_text)
            else:
                # ‚îÄ‚îÄ STEP 5: Fallback to general-purpose LLM brain ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                self.fallback_to_llm(raw_text)
        finally:
            # This block runs before any `return` in the `try` block,
            # and also if the `try` block completes normally, ensuring the
            # queue is always processed after an interaction.
            self.process_notification_queue(context="busy")
            self.last_interaction_time = time.time()
            logger.debug("Conversation processed successfully")

    def cleanup_audio_resources(self):
        """Safely cleanup audio resources to prevent device lock."""
        logger.debug("Starting audio resource cleanup")
        try:
            # Stop VAD monitor thread first
            self.stop_vad_monitor()
            
            # Kill any active TTS process
            if self.current_tts_process:
                try:
                    self.current_tts_process.kill()
                    logger.debug("TTS process killed")
                except Exception as e:
                    logger.debug("TTS process kill skip: %s", e)
                self.current_tts_process = None
            
            # Reset speaking flag
            self.is_speaking = False
            
            # Clean up recorder
            if self.recorder is not None:
                try:
                    if hasattr(self.recorder, 'stop'):
                        self.recorder.stop()
                        logger.debug("Recorder stopped")
                except Exception as e:
                    if "access violation" not in str(e).lower():
                        logger.warning(f"Error stopping recorder: {e}")
                try:
                    self.recorder.delete()
                    logger.debug("Recorder deleted")
                except Exception as e:
                    if "access violation" not in str(e).lower():
                        logger.warning(f"Error deleting recorder: {e}")
                self.recorder = None
                self.log("‚úì Recorder cleaned up")
            
            # Clean up porcupine
            if self.porcupine is not None:
                try:
                    self.porcupine.delete()
                    logger.debug("Porcupine deleted")
                except Exception as e:
                    logger.warning(f"Error deleting porcupine: {e}")
                self.porcupine = None
                self.log("‚úì Porcupine cleaned up")
            
            logger.info("Audio resources cleanup complete")
        except Exception as e:
            self.log(f"Cleanup Error: {e}")
            logger.error(f"Cleanup failed: {e}", exc_info=True)
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")anup_audio_resources'):
            logger.info("Final cleanup...")
            app.is_listening = False
            app.cleanup_audio_resources()
        logger.info("Application terminated")
        print("Jarvis GT2 stopped.")